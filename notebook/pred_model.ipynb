{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('../data/PandasData/Modified/PID001_NSL.pkl')\n",
    "numeric_df = df.select_dtypes(include=[np.number])\n",
    "numeric_df.drop(columns=['Timestamp', 'start_station_X', 'start_station_Y', 'end_station_X', 'end_station_Y',\n",
    "       'distance_from_start_station_X', 'distance_from_start_station_Y',\n",
    "       'distance_from_end_station_X', 'distance_from_end_station_Y','AGV distance X', 'AGV distance Y', ], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries = numeric_df.values.astype('float32')\n",
    "\n",
    "# train-test split for time series\n",
    "train_size = int(len(timeseries) * 0.67)\n",
    "test_size = len(timeseries) - train_size\n",
    "train, test = timeseries[:train_size], timeseries[train_size:]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_train = scaler.fit_transform(train)\n",
    "scaled_test = scaler.transform(test)\n",
    "\n",
    "def create_dataset(dataset, lookback):\n",
    "    \"\"\"Transform a time series into a prediction dataset\n",
    "    \n",
    "    Args:\n",
    "        dataset: A numpy array of time series, first dimension is the time steps\n",
    "        lookback: Size of window for prediction\n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    "    for i in range(len(dataset)-lookback):\n",
    "        feature = dataset[i:i+lookback]\n",
    "        target = dataset[i+1:i+lookback+1]\n",
    "        X.append(feature)\n",
    "        y.append(target)\n",
    "    return torch.tensor(X), torch.tensor(y)\n",
    " \n",
    "# lookback = 4\n",
    "# X_train, y_train = create_dataset(train, lookback=lookback)\n",
    "# X_test, y_test = create_dataset(test, lookback=lookback)\n",
    "\n",
    "lookback = 4\n",
    "X_train, y_train = create_dataset(scaled_train, lookback=lookback)\n",
    "X_test, y_test = create_dataset(scaled_test, lookback=lookback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([54, 4, 21]),\n",
       " torch.Size([54, 4, 21]),\n",
       " torch.Size([25, 4, 21]),\n",
       " torch.Size([25, 4, 21]))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TraPredModel(nn.Module):\n",
    "    def __init__(self, input_size = None, lookback = None):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=50, num_layers=lookback, batch_first=True)\n",
    "        self.linear = nn.Linear(50, 2)\n",
    "    def forward(self, x):\n",
    "        x, _ = self.lstm(x)\n",
    "        x = self.linear(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TraPredModel(input_size=numeric_df.shape[1], lookback=lookback)\n",
    "for name, param in model.named_parameters():\n",
    "    if 'weight_ih' in name:  # Input-hidden weights of the LSTM\n",
    "        torch.nn.init.xavier_uniform_(param.data)\n",
    "    elif 'weight_hh' in name:  # Hidden-hidden weights of the LSTM\n",
    "        torch.nn.init.orthogonal_(param.data)\n",
    "    elif 'weight' in name:  # Weights of linear layers\n",
    "        torch.nn.init.kaiming_uniform_(param.data)\n",
    "    elif 'bias' in name:  # Biases\n",
    "        param.data.fill_(0.01)\n",
    "\n",
    "\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-3)\n",
    "loss_fn = nn.MSELoss()\n",
    "train_ds = DataLoader(TensorDataset(X_train, y_train), shuffle=True, batch_size=8)\n",
    "test_ds = DataLoader(TensorDataset(X_test, y_test), shuffle=False, batch_size=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(nan, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.4835, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.6602, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.0034, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.0708, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.6273, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.2517, grad_fn=<MseLossBackward0>)\n",
      "[0.8744215369224548, 3.962294578552246, 6.719480514526367]\n",
      "Epoch 0: test RMSE 2.8890\n",
      "tensor(1.1619, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.5570, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.2624, grad_fn=<MseLossBackward0>)\n",
      "tensor(nan, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.0986, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.3755, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.8585, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9863, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.7495, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.6802, grad_fn=<MseLossBackward0>)\n",
      "tensor(nan, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.3442, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.6503, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.1569, grad_fn=<MseLossBackward0>)\n",
      "[0.8744215369224548, 3.962294578552246, 6.719480514526367]\n",
      "Epoch 2: test RMSE 2.8890\n",
      "tensor(1.3977, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.6143, grad_fn=<MseLossBackward0>)\n",
      "tensor(nan, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9499, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.1947, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.0936, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.8645, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9737, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9222, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.1598, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.0295, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.3475, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.7578, grad_fn=<MseLossBackward0>)\n",
      "tensor(nan, grad_fn=<MseLossBackward0>)\n",
      "[0.8744215369224548, 3.962294578552246, 6.719480514526367]\n",
      "Epoch 4: test RMSE 2.8890\n",
      "tensor(0.8507, grad_fn=<MseLossBackward0>)\n",
      "tensor(nan, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.8299, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.1148, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.8458, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.7288, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9458, grad_fn=<MseLossBackward0>)\n",
      "tensor(nan, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.3935, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.2050, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.5138, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.7034, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.0034, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.2838, grad_fn=<MseLossBackward0>)\n",
      "[0.8744215369224548, 3.962294578552246, 6.719480514526367]\n",
      "Epoch 6: test RMSE 2.8890\n",
      "tensor(1.4774, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.1260, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9732, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.4054, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.7093, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.5285, grad_fn=<MseLossBackward0>)\n",
      "tensor(nan, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.6476, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.8423, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.0020, grad_fn=<MseLossBackward0>)\n",
      "tensor(nan, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.2606, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.7515, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.8573, grad_fn=<MseLossBackward0>)\n",
      "[0.8744215369224548, 3.962294578552246, 6.719480514526367]\n",
      "Epoch 8: test RMSE 2.8890\n",
      "tensor(1.0635, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.7089, grad_fn=<MseLossBackward0>)\n",
      "tensor(nan, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.0274, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.3134, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.1721, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.0752, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.2381, grad_fn=<MseLossBackward0>)\n",
      "tensor(nan, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.6735, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9447, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.9092, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9065, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.6139, grad_fn=<MseLossBackward0>)\n",
      "[0.8744215369224548, 3.962294578552246, 6.719480514526367]\n",
      "Epoch 10: test RMSE 2.8890\n",
      "tensor(1.1741, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9499, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.4566, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.6894, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.5025, grad_fn=<MseLossBackward0>)\n",
      "tensor(nan, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.7439, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.3834, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.0268, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.4894, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.8600, grad_fn=<MseLossBackward0>)\n",
      "tensor(nan, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.8577, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.7512, grad_fn=<MseLossBackward0>)\n",
      "[0.8744215369224548, 3.962294578552246, 6.719480514526367]\n",
      "Epoch 12: test RMSE 2.8890\n",
      "tensor(0.5387, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.4013, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.5359, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.1482, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.7644, grad_fn=<MseLossBackward0>)\n",
      "tensor(nan, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9486, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.8628, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.8130, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.6502, grad_fn=<MseLossBackward0>)\n",
      "tensor(nan, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.1555, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.5441, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.2460, grad_fn=<MseLossBackward0>)\n",
      "[0.8744215369224548, 3.962294578552246, 6.719480514526367]\n",
      "Epoch 14: test RMSE 2.8890\n",
      "tensor(nan, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.0178, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.7672, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.4018, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.0647, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.8026, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.0047, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.3436, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.4011, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.6365, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.1001, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.0087, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.7274, grad_fn=<MseLossBackward0>)\n",
      "tensor(nan, grad_fn=<MseLossBackward0>)\n",
      "[0.8744215369224548, 3.962294578552246, 6.719480514526367]\n",
      "Epoch 16: test RMSE 2.8890\n",
      "tensor(0.5383, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.8034, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.3036, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.1083, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.1630, grad_fn=<MseLossBackward0>)\n",
      "tensor(nan, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.2412, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.1070, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.8119, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.0460, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.3368, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.6205, grad_fn=<MseLossBackward0>)\n",
      "tensor(nan, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.8802, grad_fn=<MseLossBackward0>)\n",
      "[0.8744215369224548, 3.962294578552246, 6.719480514526367]\n",
      "Epoch 18: test RMSE 2.8890\n",
      "tensor(0.9517, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9272, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.1625, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.0262, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.0134, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9280, grad_fn=<MseLossBackward0>)\n",
      "tensor(nan, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.8907, grad_fn=<MseLossBackward0>)\n",
      "tensor(nan, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.6573, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9652, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.6066, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.5176, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.6456, grad_fn=<MseLossBackward0>)\n",
      "[0.8744215369224548, 3.962294578552246, 6.719480514526367]\n",
      "Epoch 20: test RMSE 2.8890\n",
      "tensor(1.1707, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.0141, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.6874, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.0766, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9128, grad_fn=<MseLossBackward0>)\n",
      "tensor(nan, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.7318, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.5069, grad_fn=<MseLossBackward0>)\n",
      "tensor(nan, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.7707, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.3769, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.5006, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.7812, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.2580, grad_fn=<MseLossBackward0>)\n",
      "[0.8744215369224548, 3.962294578552246, 6.719480514526367]\n",
      "Epoch 22: test RMSE 2.8890\n",
      "tensor(1.1028, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.7460, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9460, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.4864, grad_fn=<MseLossBackward0>)\n",
      "tensor(nan, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.5751, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.4092, grad_fn=<MseLossBackward0>)\n",
      "tensor(nan, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.5832, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.7663, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.8080, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.2135, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.6948, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.1190, grad_fn=<MseLossBackward0>)\n",
      "[0.8744215369224548, 3.962294578552246, 6.719480514526367]\n",
      "Epoch 24: test RMSE 2.8890\n",
      "tensor(0.7996, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.2443, grad_fn=<MseLossBackward0>)\n",
      "tensor(nan, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.5938, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.5015, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.0816, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9216, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9836, grad_fn=<MseLossBackward0>)\n",
      "tensor(nan, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.7945, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.7267, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.2164, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.1416, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.1634, grad_fn=<MseLossBackward0>)\n",
      "[0.8744215369224548, 3.962294578552246, 6.719480514526367]\n",
      "Epoch 26: test RMSE 2.8890\n",
      "tensor(1.0317, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.3506, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.6930, grad_fn=<MseLossBackward0>)\n",
      "tensor(nan, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9038, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.8058, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.5619, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.6945, grad_fn=<MseLossBackward0>)\n",
      "tensor(nan, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.6704, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.3329, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.8250, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.5470, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.1480, grad_fn=<MseLossBackward0>)\n",
      "[0.8744215369224548, 3.962294578552246, 6.719480514526367]\n",
      "Epoch 28: test RMSE 2.8890\n",
      "tensor(1.1853, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.0674, grad_fn=<MseLossBackward0>)\n",
      "tensor(nan, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.6124, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.6947, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.0296, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.5169, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.0086, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.5711, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.0939, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.8580, grad_fn=<MseLossBackward0>)\n",
      "tensor(nan, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.8722, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9884, grad_fn=<MseLossBackward0>)\n",
      "[0.8744215369224548, 3.962294578552246, 6.719480514526367]\n",
      "Epoch 30: test RMSE 2.8890\n",
      "tensor(0.6097, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9168, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.6828, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.0850, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9883, grad_fn=<MseLossBackward0>)\n",
      "tensor(nan, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.6920, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.6528, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.0229, grad_fn=<MseLossBackward0>)\n",
      "tensor(nan, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.8153, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.6716, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.0949, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.8135, grad_fn=<MseLossBackward0>)\n",
      "[0.8744215369224548, 3.962294578552246, 6.719480514526367]\n",
      "Epoch 32: test RMSE 2.8890\n",
      "tensor(1.7366, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.7120, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9137, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.2896, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.7140, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9395, grad_fn=<MseLossBackward0>)\n",
      "tensor(nan, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.6128, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.6427, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.5639, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.1163, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.7168, grad_fn=<MseLossBackward0>)\n",
      "tensor(nan, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.8052, grad_fn=<MseLossBackward0>)\n",
      "[0.8744215369224548, 3.962294578552246, 6.719480514526367]\n",
      "Epoch 34: test RMSE 2.8890\n",
      "tensor(nan, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.8097, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.3873, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.8378, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.0794, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.3687, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.3572, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.0543, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.8895, grad_fn=<MseLossBackward0>)\n",
      "tensor(nan, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.7433, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9897, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.7250, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.2326, grad_fn=<MseLossBackward0>)\n",
      "[0.8744215369224548, 3.962294578552246, 6.719480514526367]\n",
      "Epoch 36: test RMSE 2.8890\n",
      "tensor(nan, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.4248, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.3361, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.7501, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.6359, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.3650, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.8647, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.6926, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.1726, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.2925, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9986, grad_fn=<MseLossBackward0>)\n",
      "tensor(nan, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.1947, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.7006, grad_fn=<MseLossBackward0>)\n",
      "[0.8744215369224548, 3.962294578552246, 6.719480514526367]\n",
      "Epoch 38: test RMSE 2.8890\n",
      "tensor(1.0986, grad_fn=<MseLossBackward0>)\n",
      "tensor(nan, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.4685, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.7849, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.2228, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9438, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.8769, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.1099, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.0724, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.3692, grad_fn=<MseLossBackward0>)\n",
      "tensor(nan, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.7882, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.7388, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.8320, grad_fn=<MseLossBackward0>)\n",
      "[0.8744215369224548, 3.962294578552246, 6.719480514526367]\n",
      "Epoch 40: test RMSE 2.8890\n",
      "tensor(0.7233, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.0389, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.4982, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.8763, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.6626, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.2213, grad_fn=<MseLossBackward0>)\n",
      "tensor(nan, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.1058, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.0396, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.3231, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.7882, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9472, grad_fn=<MseLossBackward0>)\n",
      "tensor(nan, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.8255, grad_fn=<MseLossBackward0>)\n",
      "[0.8744215369224548, 3.962294578552246, 6.719480514526367]\n",
      "Epoch 42: test RMSE 2.8890\n",
      "tensor(1.1210, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.8336, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.4996, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.1587, grad_fn=<MseLossBackward0>)\n",
      "tensor(nan, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9884, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9867, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9459, grad_fn=<MseLossBackward0>)\n",
      "tensor(nan, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9070, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.2874, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.6364, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.7858, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.2996, grad_fn=<MseLossBackward0>)\n",
      "[0.8744215369224548, 3.962294578552246, 6.719480514526367]\n",
      "Epoch 44: test RMSE 2.8890\n",
      "tensor(1.0683, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9331, grad_fn=<MseLossBackward0>)\n",
      "tensor(nan, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.3623, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.8285, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.8445, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.5891, grad_fn=<MseLossBackward0>)\n",
      "tensor(nan, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.2539, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.7973, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.3115, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.8562, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.8594, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.0422, grad_fn=<MseLossBackward0>)\n",
      "[0.8744215369224548, 3.962294578552246, 6.719480514526367]\n",
      "Epoch 46: test RMSE 2.8890\n",
      "tensor(0.7648, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.0065, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.1777, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9970, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9955, grad_fn=<MseLossBackward0>)\n",
      "tensor(nan, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.7762, grad_fn=<MseLossBackward0>)\n",
      "tensor(nan, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.4319, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.0658, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.8897, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.7642, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.7661, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.0463, grad_fn=<MseLossBackward0>)\n",
      "[0.8744215369224548, 3.962294578552246, 6.719480514526367]\n",
      "Epoch 48: test RMSE 2.8890\n",
      "tensor(1.1578, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.7264, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.7547, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.3105, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.2999, grad_fn=<MseLossBackward0>)\n",
      "tensor(nan, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.6333, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.8822, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.1126, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.2355, grad_fn=<MseLossBackward0>)\n",
      "tensor(nan, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9041, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.6632, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.6061, grad_fn=<MseLossBackward0>)\n",
      "[0.8744215369224548, 3.962294578552246, 6.719480514526367]\n",
      "Epoch 50: test RMSE 2.8890\n",
      "tensor(nan, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.0529, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.2981, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.3042, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.5851, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9775, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.6596, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.1480, grad_fn=<MseLossBackward0>)\n",
      "tensor(nan, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9167, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.1311, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.8724, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.7147, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9414, grad_fn=<MseLossBackward0>)\n",
      "[0.8744215369224548, 3.962294578552246, 6.719480514526367]\n",
      "Epoch 52: test RMSE 2.8890\n",
      "tensor(0.7405, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.6793, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.2375, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9007, grad_fn=<MseLossBackward0>)\n",
      "tensor(nan, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.8937, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.7808, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.0542, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9236, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.7388, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9254, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9942, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.3515, grad_fn=<MseLossBackward0>)\n",
      "tensor(nan, grad_fn=<MseLossBackward0>)\n",
      "[0.8744215369224548, 3.962294578552246, 6.719480514526367]\n",
      "Epoch 54: test RMSE 2.8890\n",
      "tensor(0.6519, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.8155, grad_fn=<MseLossBackward0>)\n",
      "tensor(nan, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.4212, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.4291, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.8903, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.7658, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.2085, grad_fn=<MseLossBackward0>)\n",
      "tensor(nan, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.6689, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.1117, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.4359, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.7910, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.5399, grad_fn=<MseLossBackward0>)\n",
      "[0.8744215369224548, 3.962294578552246, 6.719480514526367]\n",
      "Epoch 56: test RMSE 2.8890\n",
      "tensor(0.6844, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.1803, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.1105, grad_fn=<MseLossBackward0>)\n",
      "tensor(nan, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.6111, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.7906, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.2714, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.0074, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9799, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.4364, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.3396, grad_fn=<MseLossBackward0>)\n",
      "tensor(nan, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.6607, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.0414, grad_fn=<MseLossBackward0>)\n",
      "[0.8744215369224548, 3.962294578552246, 6.719480514526367]\n",
      "Epoch 58: test RMSE 2.8890\n",
      "tensor(0.8157, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.6185, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.5792, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.0685, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.0549, grad_fn=<MseLossBackward0>)\n",
      "tensor(nan, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.8763, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.3563, grad_fn=<MseLossBackward0>)\n",
      "tensor(nan, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9265, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.5323, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.1032, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.0710, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9420, grad_fn=<MseLossBackward0>)\n",
      "[0.8744215369224548, 3.962294578552246, 6.719480514526367]\n",
      "Epoch 60: test RMSE 2.8890\n",
      "tensor(0.6815, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.6871, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.0177, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.7546, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.2330, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.8356, grad_fn=<MseLossBackward0>)\n",
      "tensor(nan, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.0207, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9260, grad_fn=<MseLossBackward0>)\n",
      "tensor(nan, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.6622, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.2351, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.7234, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.8470, grad_fn=<MseLossBackward0>)\n",
      "[0.8744215369224548, 3.962294578552246, 6.719480514526367]\n",
      "Epoch 62: test RMSE 2.8890\n",
      "tensor(0.8563, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.5634, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9531, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.7125, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.8358, grad_fn=<MseLossBackward0>)\n",
      "tensor(nan, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.3003, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.8138, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.4191, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.3524, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.6991, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.4000, grad_fn=<MseLossBackward0>)\n",
      "tensor(nan, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.7293, grad_fn=<MseLossBackward0>)\n",
      "[0.8744215369224548, 3.962294578552246, 6.719480514526367]\n",
      "Epoch 64: test RMSE 2.8890\n",
      "tensor(nan, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.6315, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.1492, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.5409, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.1717, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.7636, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.5129, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.7074, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.6349, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.2243, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.7224, grad_fn=<MseLossBackward0>)\n",
      "tensor(nan, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.6827, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.0777, grad_fn=<MseLossBackward0>)\n",
      "[0.8744215369224548, 3.962294578552246, 6.719480514526367]\n",
      "Epoch 66: test RMSE 2.8890\n",
      "tensor(1.3841, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.1174, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.8003, grad_fn=<MseLossBackward0>)\n",
      "tensor(nan, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.7152, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.1720, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.3543, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.0403, grad_fn=<MseLossBackward0>)\n",
      "tensor(nan, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9715, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.5838, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.0870, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.4815, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.1576, grad_fn=<MseLossBackward0>)\n",
      "[0.8744215369224548, 3.962294578552246, 6.719480514526367]\n",
      "Epoch 68: test RMSE 2.8890\n",
      "tensor(1.0250, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.7338, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.6332, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.0607, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.1554, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.1967, grad_fn=<MseLossBackward0>)\n",
      "tensor(nan, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.8977, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.7669, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.0902, grad_fn=<MseLossBackward0>)\n",
      "tensor(nan, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.0720, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.4609, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.0376, grad_fn=<MseLossBackward0>)\n",
      "[0.8744215369224548, 3.962294578552246, 6.719480514526367]\n",
      "Epoch 70: test RMSE 2.8890\n",
      "tensor(1.0449, grad_fn=<MseLossBackward0>)\n",
      "tensor(nan, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.4717, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.4629, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.5503, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.7347, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.0310, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.1433, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.0702, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.1446, grad_fn=<MseLossBackward0>)\n",
      "tensor(nan, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.7855, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.1662, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.6509, grad_fn=<MseLossBackward0>)\n",
      "[0.8744215369224548, 3.962294578552246, 6.719480514526367]\n",
      "Epoch 72: test RMSE 2.8890\n",
      "tensor(1.1648, grad_fn=<MseLossBackward0>)\n",
      "tensor(nan, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.5395, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.1125, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9887, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.1559, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.3689, grad_fn=<MseLossBackward0>)\n",
      "tensor(nan, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9835, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.2579, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.2875, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.8310, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9132, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.7434, grad_fn=<MseLossBackward0>)\n",
      "[0.8744215369224548, 3.962294578552246, 6.719480514526367]\n",
      "Epoch 74: test RMSE 2.8890\n",
      "tensor(nan, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.5169, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.7660, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.7059, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9205, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.4230, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.7543, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.7177, grad_fn=<MseLossBackward0>)\n",
      "tensor(nan, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.2056, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.2758, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.5527, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9345, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.6252, grad_fn=<MseLossBackward0>)\n",
      "[0.8744215369224548, 3.962294578552246, 6.719480514526367]\n",
      "Epoch 76: test RMSE 2.8890\n",
      "tensor(0.9936, grad_fn=<MseLossBackward0>)\n",
      "tensor(nan, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9340, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.3941, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.2323, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.7735, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.4736, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.7831, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.1504, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.7756, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.4602, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.8468, grad_fn=<MseLossBackward0>)\n",
      "tensor(nan, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.6404, grad_fn=<MseLossBackward0>)\n",
      "[0.8744215369224548, 3.962294578552246, 6.719480514526367]\n",
      "Epoch 78: test RMSE 2.8890\n",
      "tensor(0.8583, grad_fn=<MseLossBackward0>)\n",
      "tensor(nan, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.8841, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.5197, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.0654, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.0930, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.4689, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.0518, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.8219, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.8169, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9302, grad_fn=<MseLossBackward0>)\n",
      "tensor(nan, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.6709, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.8638, grad_fn=<MseLossBackward0>)\n",
      "[0.8744215369224548, 3.962294578552246, 6.719480514526367]\n",
      "Epoch 80: test RMSE 2.8890\n",
      "tensor(1.1285, grad_fn=<MseLossBackward0>)\n",
      "tensor(nan, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.0796, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.6621, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.0955, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.5551, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.7553, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.1723, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.5758, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.1556, grad_fn=<MseLossBackward0>)\n",
      "tensor(nan, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.6300, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.7987, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.6019, grad_fn=<MseLossBackward0>)\n",
      "[0.8744215369224548, 3.962294578552246, 6.719480514526367]\n",
      "Epoch 82: test RMSE 2.8890\n",
      "tensor(1.0550, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.7940, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.8346, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.7717, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.6025, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.0448, grad_fn=<MseLossBackward0>)\n",
      "tensor(nan, grad_fn=<MseLossBackward0>)\n",
      "tensor(nan, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9709, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.8243, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.5879, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.2885, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9457, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.6155, grad_fn=<MseLossBackward0>)\n",
      "[0.8744215369224548, 3.962294578552246, 6.719480514526367]\n",
      "Epoch 84: test RMSE 2.8890\n",
      "tensor(nan, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.1693, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.0609, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.8722, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.3913, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9966, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.5794, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.7303, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.5376, grad_fn=<MseLossBackward0>)\n",
      "tensor(nan, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9327, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.8087, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.2771, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.7143, grad_fn=<MseLossBackward0>)\n",
      "[0.8744215369224548, 3.962294578552246, 6.719480514526367]\n",
      "Epoch 86: test RMSE 2.8890\n",
      "tensor(nan, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.9042, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.6826, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9063, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.5614, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.8765, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.3890, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.2531, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.0656, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9016, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.3243, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.0401, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.8716, grad_fn=<MseLossBackward0>)\n",
      "tensor(nan, grad_fn=<MseLossBackward0>)\n",
      "[0.8744215369224548, 3.962294578552246, 6.719480514526367]\n",
      "Epoch 88: test RMSE 2.8890\n",
      "tensor(1.4540, grad_fn=<MseLossBackward0>)\n",
      "tensor(nan, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.1254, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.6444, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.7988, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.0721, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9104, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.6648, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.1932, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9311, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9743, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.3118, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.1832, grad_fn=<MseLossBackward0>)\n",
      "tensor(nan, grad_fn=<MseLossBackward0>)\n",
      "[0.8744215369224548, 3.962294578552246, 6.719480514526367]\n",
      "Epoch 90: test RMSE 2.8890\n",
      "tensor(0.8947, grad_fn=<MseLossBackward0>)\n",
      "tensor(nan, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.2942, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.1788, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.6080, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.1226, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.1862, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.1437, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9795, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.2565, grad_fn=<MseLossBackward0>)\n",
      "tensor(nan, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.6284, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9068, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.0536, grad_fn=<MseLossBackward0>)\n",
      "[0.8744215369224548, 3.962294578552246, 6.719480514526367]\n",
      "Epoch 92: test RMSE 2.8890\n",
      "tensor(1.1637, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9372, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.0814, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9910, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.0221, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.7748, grad_fn=<MseLossBackward0>)\n",
      "tensor(nan, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.1580, grad_fn=<MseLossBackward0>)\n",
      "tensor(nan, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.8096, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.8360, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.8343, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.4897, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.0575, grad_fn=<MseLossBackward0>)\n",
      "[0.8744215369224548, 3.962294578552246, 6.719480514526367]\n",
      "Epoch 94: test RMSE 2.8890\n",
      "tensor(0.9751, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.0203, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9589, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.4613, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.7275, grad_fn=<MseLossBackward0>)\n",
      "tensor(nan, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.2594, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.2801, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.1248, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9595, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.0602, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9335, grad_fn=<MseLossBackward0>)\n",
      "tensor(nan, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.7092, grad_fn=<MseLossBackward0>)\n",
      "[0.8744215369224548, 3.962294578552246, 6.719480514526367]\n",
      "Epoch 96: test RMSE 2.8890\n",
      "tensor(0.9501, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.8042, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.3045, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.0269, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9090, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.3538, grad_fn=<MseLossBackward0>)\n",
      "tensor(nan, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.6866, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.8592, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9080, grad_fn=<MseLossBackward0>)\n",
      "tensor(nan, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.7236, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9400, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.3340, grad_fn=<MseLossBackward0>)\n",
      "[0.8744215369224548, 3.962294578552246, 6.719480514526367]\n",
      "Epoch 98: test RMSE 2.8890\n",
      "tensor(0.4188, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.2249, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.0654, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.6849, grad_fn=<MseLossBackward0>)\n",
      "tensor(nan, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.8502, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.0971, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 100\n",
    "model = TraPredModel(input_size=numeric_df.shape[1], lookback=lookback)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    for X_batch, y_batch in train_ds:\n",
    "        y_pred = model(X_batch)\n",
    "        loss = loss_fn(y_pred, y_batch[:, :, -2:])\n",
    "        optimizer.zero_grad()\n",
    "        print(loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Validation\n",
    "    if epoch % 2 == 0:\n",
    "        with torch.no_grad():\n",
    "            all_test = len(test_ds)\n",
    "            test_rmse_all = []\n",
    "            for X_test_batch, y_test_batch in test_ds:\n",
    "                y_pred = model(X_test_batch)\n",
    "\n",
    "                test_rmse = np.sqrt(loss_fn(y_pred, y_test_batch[:, :, -2:]))\n",
    "                if not torch.isnan(test_rmse):\n",
    "                    test_rmse_all.append(test_rmse.item())\n",
    "\n",
    "            print(test_rmse_all)\n",
    "            \n",
    "            print(\"Epoch %d: test RMSE %.4f\" % (epoch, sum(test_rmse_all)/all_test))\n",
    "    # break\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_rmse.item() == float('nan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[2.8357e-04, 6.6137e-03],\n",
       "         [2.6307e-04, 6.1712e-03],\n",
       "         [2.1249e-04, 5.0802e-03],\n",
       "         [1.6734e-04, 4.1370e-03]],\n",
       "\n",
       "        [[3.2650e-01, 3.0699e-01],\n",
       "         [2.7231e-01, 2.7397e-01],\n",
       "         [2.2124e-01, 1.9812e-01],\n",
       "         [1.6293e-01, 1.8219e-01]],\n",
       "\n",
       "        [[1.6734e-04, 4.1370e-03],\n",
       "         [1.6734e-04, 4.1370e-03],\n",
       "         [1.6734e-04, 4.1370e-03],\n",
       "         [1.6734e-04, 4.1370e-03]],\n",
       "\n",
       "        [[1.0000e+00, 7.7372e-02],\n",
       "         [9.9989e-01, 9.5654e-02],\n",
       "         [9.9989e-01, 9.5654e-02],\n",
       "         [9.9989e-01, 9.5654e-02]],\n",
       "\n",
       "        [[1.3000e-04, 3.1300e-03],\n",
       "         [1.3000e-04, 3.1300e-03],\n",
       "         [1.3000e-04, 3.1300e-03],\n",
       "         [1.2544e-04, 3.0155e-03]],\n",
       "\n",
       "        [[1.6734e-04, 4.1370e-03],\n",
       "         [1.3232e-04, 3.1929e-03],\n",
       "         [1.3000e-04, 3.1300e-03],\n",
       "         [1.3000e-04, 3.1300e-03]],\n",
       "\n",
       "        [[1.6293e-01, 1.8219e-01],\n",
       "         [1.1653e-01, 2.5023e-01],\n",
       "         [6.7933e-02, 2.6236e-01],\n",
       "         [2.3676e-02, 1.6142e-01]],\n",
       "\n",
       "        [[2.7987e-04, 8.5220e-03],\n",
       "         [2.8357e-04, 6.6137e-03],\n",
       "         [2.8357e-04, 6.6137e-03],\n",
       "         [2.8357e-04, 6.6137e-03]]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_batch[:, :, -2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0786,  0.0392],\n",
       "         [-0.0636,  0.0486],\n",
       "         [-0.0565,  0.0533],\n",
       "         [-0.0530,  0.0557]],\n",
       "\n",
       "        [[-0.0786,  0.0392],\n",
       "         [-0.0636,  0.0486],\n",
       "         [-0.0564,  0.0533],\n",
       "         [-0.0530,  0.0556]],\n",
       "\n",
       "        [[-0.0786,  0.0392],\n",
       "         [-0.0636,  0.0486],\n",
       "         [-0.0565,  0.0534],\n",
       "         [-0.0530,  0.0557]],\n",
       "\n",
       "        [[-0.0785,  0.0392],\n",
       "         [-0.0634,  0.0485],\n",
       "         [-0.0560,  0.0532],\n",
       "         [-0.0524,  0.0555]],\n",
       "\n",
       "        [[-0.0786,  0.0392],\n",
       "         [-0.0636,  0.0486],\n",
       "         [-0.0565,  0.0534],\n",
       "         [-0.0530,  0.0557]],\n",
       "\n",
       "        [[-0.0786,  0.0392],\n",
       "         [-0.0636,  0.0486],\n",
       "         [-0.0565,  0.0534],\n",
       "         [-0.0530,  0.0557]],\n",
       "\n",
       "        [[-0.0786,  0.0392],\n",
       "         [-0.0635,  0.0486],\n",
       "         [-0.0564,  0.0534],\n",
       "         [-0.0530,  0.0557]],\n",
       "\n",
       "        [[-0.0786,  0.0392],\n",
       "         [-0.0636,  0.0487],\n",
       "         [-0.0565,  0.0534],\n",
       "         [-0.0530,  0.0557]]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(27025266., grad_fn=<MseLossBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[2036.3741, 6182.6597],\n",
       "         [1838.5870, 6191.6587],\n",
       "         [1658.4749, 6116.8018],\n",
       "         [1571.1934, 6015.2192]],\n",
       "\n",
       "        [[1563.2740, 6001.9951],\n",
       "         [1563.2740, 6001.9951],\n",
       "         [1563.1907, 6001.6665],\n",
       "         [1562.9847, 6000.8579]],\n",
       "\n",
       "        [[1563.1907, 6001.6665],\n",
       "         [1562.9847, 6000.8579],\n",
       "         [1562.8010, 6000.1582],\n",
       "         [1562.8010, 6000.1582]],\n",
       "\n",
       "        [[1562.8010, 6000.1582],\n",
       "         [1562.8010, 6000.1582],\n",
       "         [1562.8010, 6000.1582],\n",
       "         [1562.8010, 6000.1582]],\n",
       "\n",
       "        [[4166.2915, 6263.7432],\n",
       "         [3882.6104, 6264.6323],\n",
       "         [3626.2195, 6230.0762],\n",
       "         [3382.0386, 6161.8926]],\n",
       "\n",
       "        [[2462.5181, 6144.0171],\n",
       "         [2225.2104, 6132.2021],\n",
       "         [2036.3741, 6182.6597],\n",
       "         [1838.5870, 6191.6587]],\n",
       "\n",
       "        [[1562.6490, 5999.4111],\n",
       "         [1562.6490, 5999.4111],\n",
       "         [1562.6490, 5999.4111],\n",
       "         [1562.6490, 5999.4111]],\n",
       "\n",
       "        [[5629.0020, 6020.4014],\n",
       "         [5629.1602, 6019.7969],\n",
       "         [5631.8296, 6054.4697],\n",
       "         [5631.3882, 6068.0288]]])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_batch[:, :, -2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(29356700., grad_fn=<MseLossBackward0>)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn(y_pred, y_batch[:, :, -2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1562.6305, 5999.3267],\n",
       "         [1562.5750, 5999.0732],\n",
       "         [1562.3723, 5998.1821],\n",
       "         [1562.3480, 5998.0752]],\n",
       "\n",
       "        [[1563.2740, 6001.9951],\n",
       "         [1563.2740, 6001.9951],\n",
       "         [1563.2740, 6001.9951],\n",
       "         [1563.2740, 6001.9951]],\n",
       "\n",
       "        [[3626.2195, 6230.0762],\n",
       "         [3382.0386, 6161.8926],\n",
       "         [3129.8562, 6181.4565],\n",
       "         [2890.8782, 6224.7598]],\n",
       "\n",
       "        [[5631.3882, 6068.0288],\n",
       "         [5631.3882, 6068.0288],\n",
       "         [5631.3882, 6068.0288],\n",
       "         [5630.5522, 6069.1782]],\n",
       "\n",
       "        [[3382.0386, 6161.8926],\n",
       "         [3129.8562, 6181.4565],\n",
       "         [2890.8782, 6224.7598],\n",
       "         [2670.3411, 6200.2725]],\n",
       "\n",
       "        [[1562.8010, 6000.1582],\n",
       "         [1562.8010, 6000.1582],\n",
       "         [1562.8010, 6000.1582],\n",
       "         [1562.6586, 5999.4580]],\n",
       "\n",
       "        [[5629.0020, 6020.4014],\n",
       "         [5629.1602, 6019.7969],\n",
       "         [5631.8296, 6054.4697],\n",
       "         [5631.3882, 6068.0288]],\n",
       "\n",
       "        [[2890.8782, 6224.7598],\n",
       "         [2670.3411, 6200.2725],\n",
       "         [2462.5181, 6144.0171],\n",
       "         [2225.2104, 6132.2021]]])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_batch_last2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shawn/opt/anaconda3/envs/pytorch/lib/python3.11/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([8, 2, 21])) that is different to the input size (torch.Size([8, 2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(nan, grad_fn=<MseLossBackward0>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn(y_pred_last2, y_batch_last2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(numeric_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan]],\n",
       "\n",
       "        [[nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan]],\n",
       "\n",
       "        [[nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan]],\n",
       "\n",
       "        [[nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan]],\n",
       "\n",
       "        [[nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan]],\n",
       "\n",
       "        [[nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan]],\n",
       "\n",
       "        [[nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan]],\n",
       "\n",
       "        [[nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan]]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[5559.4497, 6606.9014],\n",
       "         [5542.7568, 6721.1694],\n",
       "         [5536.9160, 6738.7012],\n",
       "         [5471.5371, 6733.4746]],\n",
       "\n",
       "        [[2890.8782, 6224.7598],\n",
       "         [2670.3411, 6200.2725],\n",
       "         [2462.5181, 6144.0171],\n",
       "         [2225.2104, 6132.2021]],\n",
       "\n",
       "        [[1562.8010, 6000.1582],\n",
       "         [1562.8010, 6000.1582],\n",
       "         [1562.8010, 6000.1582],\n",
       "         [1562.8010, 6000.1582]],\n",
       "\n",
       "        [[5077.3340, 6578.1284],\n",
       "         [4839.5220, 6500.1108],\n",
       "         [4633.7700, 6408.1240],\n",
       "         [4426.0840, 6316.3164]],\n",
       "\n",
       "        [[3882.6104, 6264.6323],\n",
       "         [3626.2195, 6230.0762],\n",
       "         [3382.0386, 6161.8926],\n",
       "         [3129.8562, 6181.4565]],\n",
       "\n",
       "        [[1562.6490, 5999.4111],\n",
       "         [1562.6490, 5999.4111],\n",
       "         [1562.6490, 5999.4111],\n",
       "         [1562.6305, 5999.3267]],\n",
       "\n",
       "        [[2036.3741, 6182.6597],\n",
       "         [1838.5870, 6191.6587],\n",
       "         [1658.4749, 6116.8018],\n",
       "         [1571.1934, 6015.2192]],\n",
       "\n",
       "        [[1562.6305, 5999.3267],\n",
       "         [1562.5750, 5999.0732],\n",
       "         [1562.3723, 5998.1821],\n",
       "         [1562.3480, 5998.0752]]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_batch[:, :, -2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 4, 2])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_batch[:, :, -2:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 2.4965e-05,  6.0469e-04,  6.0521e-04,  2.0769e+00,  9.1807e-01,\n",
       "           2.2707e+00, -2.0769e+00, -9.1807e-01,  0.0000e+00,  2.0000e+00,\n",
       "           4.0000e+00,  1.4727e+03,  1.3739e+03,  5.3032e+02, -9.0132e-01,\n",
       "          -2.1056e-02, -4.2835e-01,  8.4683e+02,  6.6767e+03,  4.4261e+03,\n",
       "           6.3163e+03],\n",
       "         [ 2.3611e-05,  6.1139e-04,  6.1184e-04,  2.5979e+00,  5.2573e-01,\n",
       "           2.6506e+00, -2.5979e+00, -5.2573e-01,  0.0000e+00,  2.0000e+00,\n",
       "           4.0000e+00,  1.7021e+03,  1.6337e+03,  4.7774e+02, -8.6969e-01,\n",
       "           6.4958e-02, -4.8786e-01,  8.4683e+02,  6.6767e+03,  4.1663e+03,\n",
       "           6.2637e+03]],\n",
       "\n",
       "        [[ 2.9754e-05,  6.0510e-04,  6.0583e-04,  2.4366e-04,  1.0711e-03,\n",
       "           1.0985e-03, -2.4366e-04, -1.0711e-03,  0.0000e+00,  2.0000e+00,\n",
       "           2.0000e+00,  2.0262e+02,  4.2652e+01,  1.9807e+02, -6.0803e-01,\n",
       "          -7.7583e-01, -1.2950e-01,  8.4674e+02,  6.6746e+03,  1.5623e+03,\n",
       "           5.9981e+03],\n",
       "         [ 2.9167e-05,  6.0222e-04,  6.0293e-04,  7.4125e-04,  3.2022e-03,\n",
       "           3.2869e-03, -7.4125e-04, -3.2022e-03,  0.0000e+00,  2.0000e+00,\n",
       "           2.0000e+00,  2.0232e+02,  4.2726e+01,  1.9775e+02, -3.9413e-01,\n",
       "          -9.0882e-01, -1.3628e-01,  8.4674e+02,  6.6745e+03,  1.5623e+03,\n",
       "           5.9978e+03]],\n",
       "\n",
       "        [[ 3.4167e-05,  6.4833e-04,  6.4923e-04,  2.3781e+00,  7.8018e-01,\n",
       "           2.5028e+00, -2.3781e+00, -7.8018e-01,  0.0000e+00,  2.0000e+00,\n",
       "           4.0000e+00,  1.1969e+03,  9.6048e+02,  7.1411e+02, -8.9556e-01,\n",
       "          -1.3701e-01, -4.2247e-01,  8.4684e+02,  6.6769e+03,  4.8395e+03,\n",
       "           6.5001e+03],\n",
       "         [ 2.3230e-05,  6.1100e-04,  6.1144e-04,  2.0575e+00,  9.1987e-01,\n",
       "           2.2538e+00, -2.0575e+00, -9.1987e-01,  0.0000e+00,  2.0000e+00,\n",
       "           4.0000e+00,  1.3218e+03,  1.1662e+03,  6.2212e+02, -8.9355e-01,\n",
       "          -1.2911e-01, -4.2856e-01,  8.4684e+02,  6.6768e+03,  4.6338e+03,\n",
       "           6.4081e+03]],\n",
       "\n",
       "        [[ 2.8056e-05,  6.1708e-04,  6.1772e-04,  1.8372e-03,  6.9994e-03,\n",
       "           7.2365e-03, -1.8372e-03, -6.9994e-03,  0.0000e+00,  2.0000e+00,\n",
       "           2.0000e+00,  2.0456e+02,  4.2199e+01,  2.0016e+02, -6.0500e-01,\n",
       "          -7.6460e-01, -2.0972e-01,  8.4678e+02,  6.6754e+03,  1.5628e+03,\n",
       "           6.0002e+03],\n",
       "         [ 2.7428e-05,  6.1163e-04,  6.1225e-04,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  2.0000e+00,\n",
       "           2.0000e+00,  2.0456e+02,  4.2199e+01,  2.0016e+02, -7.5576e-01,\n",
       "          -6.3372e-01, -1.6448e-01,  8.4677e+02,  6.6753e+03,  1.5628e+03,\n",
       "           6.0002e+03]],\n",
       "\n",
       "        [[ 2.6806e-05,  6.1403e-04,  6.1461e-04,  1.5903e-04,  6.1814e-03,\n",
       "           6.1834e-03,  1.5903e-04, -6.1814e-03,  0.0000e+00,  2.0000e+00,\n",
       "           2.0000e+00,  2.0765e+02,  4.1741e+01,  2.0341e+02, -6.3683e-01,\n",
       "          -7.4357e-01, -1.5112e-01,  8.4680e+02,  6.6758e+03,  1.5633e+03,\n",
       "           6.0034e+03],\n",
       "         [ 2.7083e-05,  6.1778e-04,  6.1837e-04,  1.4986e-04,  1.4151e-02,\n",
       "           1.4151e-02,  1.4986e-04, -1.4151e-02,  0.0000e+00,  2.0000e+00,\n",
       "           2.0000e+00,  2.0626e+02,  4.1726e+01,  2.0199e+02, -7.7696e-01,\n",
       "          -6.1833e-01, -1.1631e-01,  8.4679e+02,  6.6758e+03,  1.5633e+03,\n",
       "           6.0020e+03]],\n",
       "\n",
       "        [[ 4.4438e+00,  6.5859e-03,  4.4438e+00,  5.8408e-02,  1.7531e-01,\n",
       "           1.8479e-01, -5.8408e-02,  1.7531e-01,  0.0000e+00,  1.0000e+00,\n",
       "           4.0000e+00,  9.8836e+02,  2.6308e+02,  9.5270e+02, -7.9578e-01,\n",
       "           1.4939e-01, -5.0335e-01,  9.0712e+02,  6.6763e+03,  5.5369e+03,\n",
       "           6.7387e+03],\n",
       "         [ 2.5292e-01,  8.9304e-03,  2.5308e-01,  6.5379e-01,  5.2261e-02,\n",
       "           6.5587e-01, -6.5379e-01, -5.2261e-02,  0.0000e+00,  2.0000e+00,\n",
       "           4.0000e+00,  1.0028e+03,  3.2846e+02,  9.4747e+02, -8.8329e-01,\n",
       "          -1.6083e-01, -4.3869e-01,  9.3242e+02,  6.6754e+03,  5.4715e+03,\n",
       "           6.7335e+03]],\n",
       "\n",
       "        [[ 3.0000e-05,  6.3194e-04,  6.3266e-04,  1.8500e-04,  8.4500e-04,\n",
       "           8.6501e-04, -1.8500e-04, -8.4500e-04,  0.0000e+00,  2.0000e+00,\n",
       "           2.0000e+00,  2.0378e+02,  4.2369e+01,  1.9933e+02, -5.7394e-01,\n",
       "          -7.9894e-01, -1.7792e-01,  8.4675e+02,  6.6748e+03,  1.5626e+03,\n",
       "           5.9993e+03],\n",
       "         [ 3.0417e-05,  6.1792e-04,  6.1866e-04,  5.5500e-04,  2.5350e-03,\n",
       "           2.5950e-03, -5.5500e-04, -2.5350e-03,  0.0000e+00,  2.0000e+00,\n",
       "           2.0000e+00,  2.0354e+02,  4.2425e+01,  1.9907e+02, -5.8224e-01,\n",
       "          -7.9126e-01, -1.8644e-01,  8.4674e+02,  6.6747e+03,  1.5626e+03,\n",
       "           5.9991e+03]],\n",
       "\n",
       "        [[ 2.9028e-05,  6.1222e-04,  6.1291e-04,  9.6250e-05,  4.7250e-04,\n",
       "           4.8220e-04, -9.6250e-05, -4.7250e-04,  0.0000e+00,  2.0000e+00,\n",
       "           2.0000e+00,  2.0386e+02,  4.2351e+01,  1.9941e+02, -5.8150e-01,\n",
       "          -7.9136e-01, -1.8897e-01,  8.4676e+02,  6.6750e+03,  1.5626e+03,\n",
       "           5.9994e+03],\n",
       "         [ 2.8856e-05,  6.1335e-04,  6.1403e-04,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  2.0000e+00,\n",
       "           2.0000e+00,  2.0386e+02,  4.2351e+01,  1.9941e+02, -6.0620e-01,\n",
       "          -7.7145e-01, -1.9176e-01,  8.4676e+02,  6.6750e+03,  1.5626e+03,\n",
       "           5.9994e+03]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_batch_last2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
