{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from datetime import datetime\n",
    "\n",
    "import os\n",
    "import sys\n",
    "cur_dir = os.path.dirname(os.path.abspath(\"__file__\"))  # Gets the current notebook directory\n",
    "src_dir = os.path.join(cur_dir, '../')  # Constructs the path to the 'src' directory\n",
    "# Add the 'src' directory to sys.path\n",
    "if src_dir not in sys.path:\n",
    "    sys.path.append(src_dir)\n",
    "\n",
    "from src.constant import *\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from src.MyDataset import MyDataset\n",
    "from src.TraPredModel import TraPredModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import torch.utils\n",
    "import torch.utils.data\n",
    "\n",
    "\n",
    "lookback = 20\n",
    "dir = '../data/PandasData/Sampled/'\n",
    "ds = MyDataset(lookback=lookback)\n",
    "train_batch_size = 4\n",
    "test_batch_size = 16\n",
    "\n",
    "def process_data(df_dir : str, target_freq : int = 10):\n",
    "    df: pd.DataFrame = pd.read_pickle(df_dir)\n",
    "    df.dropna(inplace=True, how='any')\n",
    "    f_per_sec = df.groupby('TimestampID').count().mean().mean()\n",
    "    if f_per_sec < target_freq:\n",
    "        raise ValueError('The frequency of the data is lower than the target frequency')\n",
    "    elif int(f_per_sec) == target_freq:\n",
    "        pass\n",
    "    else:\n",
    "        resample_ratio = int(f_per_sec/target_freq)\n",
    "        df = df.iloc[::resample_ratio, :]\n",
    "    # # for origin\n",
    "    for drop_column in ['Confidence', 'Timestamp', 'TimestampID', \n",
    "                          'DatapointID', 'PID', 'SCN', 'U_X', 'U_Y', 'U_Z', \n",
    "                          'AGV_Z', 'User_Z', 'GazeOrigin_Z', 'User_Pitch', 'User_Yaw', 'User_Roll', \n",
    "                          'EyeTarget']:\n",
    "        df = df.drop(columns=[drop_column], errors='ignore')\n",
    "\n",
    "    target_columns = ['User_X', 'User_Y']\n",
    "    # Reorder columns\n",
    "    new_columns = target_columns + [col for col in df.columns if col not in target_columns]\n",
    "    df = df[new_columns]\n",
    "\n",
    "    return df\n",
    "\n",
    "for file in os.listdir(dir):\n",
    "    if file.endswith('.pkl'):\n",
    "        df = process_data(dir+file)\n",
    "        ds.read_data(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shaoze/Documents/Boeing/Boeing-Trajectory-Prediction/notebook/../src/MyDataset.py:101: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:274.)\n",
      "  return torch.tensor(X), torch.tensor(y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "columns : Index(['User_X', 'User_Y', 'AGV_distance_X', 'AGV_distance_Y', 'AGV_speed_X',\n",
      "       'AGV_speed_Y', 'AGV_speed', 'User_speed_X', 'User_speed_Y',\n",
      "       'User_speed', 'User_velocity_X', 'User_velocity_Y', 'Wait_time',\n",
      "       'intent_to_cross', 'Gazing_station', 'possible_interaction',\n",
      "       'facing_along_sidewalk', 'facing_to_road', 'On_sidewalks', 'On_road',\n",
      "       'closest_station', 'distance_to_closest_station',\n",
      "       'distance_to_closest_station_X', 'distance_to_closest_station_Y',\n",
      "       'looking_at_AGV', 'start_station_X', 'start_station_Y', 'end_station_X',\n",
      "       'end_station_Y', 'distance_from_start_station_X',\n",
      "       'distance_from_start_station_Y', 'distance_from_end_station_X',\n",
      "       'distance_from_end_station_Y', 'facing_start_station',\n",
      "       'facing_end_station', 'GazeDirection_X', 'GazeDirection_Y',\n",
      "       'GazeDirection_Z', 'AGV_X', 'AGV_Y', 'AGV_name',\n",
      "       'looking_at_closest_station', 'rolling_avg'],\n",
      "      dtype='object') \n",
      "feature_dim : 32\n"
     ]
    }
   ],
   "source": [
    "stats_dict = {'mean': 0, 'std': 0, 'min': 0, 'max': 0}\n",
    "stats_dict = ds.normalize_dataset()\n",
    "ds.generate_data()\n",
    "\n",
    "train:torch.utils.data.DataLoader\n",
    "test:torch.utils.data.DataLoader\n",
    "\n",
    "train, test = ds.split_data(frac=0.9, shuffle=True, train_batch_size=train_batch_size, test_batch_size=test_batch_size)\n",
    "\n",
    "\n",
    "feature_dim = ds.feature_dim\n",
    "print(f\"columns : {df.columns} \\nfeature_dim : {feature_dim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 20, 32]) torch.Size([4, 20, 32])\n",
      "20562 2285\n"
     ]
    }
   ],
   "source": [
    "for i, (X, y) in enumerate(train):\n",
    "    print(X.shape, y.shape)\n",
    "    break\n",
    "\n",
    "print(len(train), len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class GatedLinearUnit(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(input_size, input_size)\n",
    "        self.gate = nn.Linear(input_size, input_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return torch.sigmoid(self.gate(x)) * self.fc(x)\n",
    "\n",
    "class TemporalFusionTransformer(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_size=64, num_heads=8, dropout=0.1, device='cpu'):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        \n",
    "        # Transformer Block\n",
    "        self.multihead_attn = nn.MultiheadAttention(embed_dim=hidden_size, num_heads=num_heads, dropout=dropout, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.layer_norm = nn.LayerNorm(hidden_size)\n",
    "        \n",
    "        # Gated Linear Unit Networks\n",
    "        self.glu = GatedLinearUnit(hidden_size)\n",
    "\n",
    "        # Fully connected output network\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        # Initial transformation\n",
    "        x = self.fc1(x)\n",
    "\n",
    "        # Applying Transformer Block\n",
    "        attn_output, _ = self.multihead_attn(x, x, x, key_padding_mask=mask)\n",
    "        x = x + self.dropout(attn_output)\n",
    "        x = self.layer_norm(x)\n",
    "\n",
    "        # Gated Linear Unit\n",
    "        x = self.glu(x)\n",
    "        \n",
    "        # Final output layer\n",
    "        x = self.fc2(self.activation(x))\n",
    "        return x\n",
    "\n",
    "class TraPredModel(nn.Module):\n",
    "    def __init__(self, input_size=None, lookback=None, layers=[256, 256], hidden_size=64, bidirectional=True, device='cpu'):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = lookback\n",
    "        self.device = device\n",
    "        \n",
    "        # TFT\n",
    "        self.TFT = TemporalFusionTransformer(input_size=feature_dim, output_size=feature_dim, hidden_size=64, num_heads=8, dropout=0.1, device=device)\n",
    "\n",
    "        # Encoder LSTM\n",
    "        self.encoder_lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=lookback, batch_first=True, bidirectional=bidirectional, dropout=0.1)\n",
    "\n",
    "        # Decoder LSTM\n",
    "        self.decoder_lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=lookback, batch_first=True, bidirectional=bidirectional, dropout=0.1)\n",
    "\n",
    "        self.bi = 2 if bidirectional else 1\n",
    "        neuron_num = hidden_size * self.bi\n",
    "\n",
    "        mlp_layers = []\n",
    "        in_features = neuron_num\n",
    "        layers.append(input_size)\n",
    "        for out_features in layers:\n",
    "            mlp_layers.append(nn.Linear(in_features, out_features))\n",
    "            mlp_layers.append(nn.ReLU())  # Adding ReLU activation function after each Linear layer\n",
    "            mlp_layers.append(nn.Dropout(0.2))  # Adding dropout layer\n",
    "            in_features = out_features  # Update in_features for the next layer\n",
    "        \n",
    "        mlp_layers.pop()  # Remove the last ReLU added in the loop\n",
    "        mlp_layers.pop()  # Remove the last Dropout added in the loop\n",
    "        \n",
    "        self.mlp = nn.Sequential(*mlp_layers)\n",
    "\n",
    "    def forward(self, x, future_steps=5):\n",
    "        \n",
    "        # Encoding\n",
    "        x = self.TFT(x)\n",
    "        \n",
    "        encoder_out, (h_n, c_n) = self.encoder_lstm(x)\n",
    "\n",
    "        # Prepare the decoder input (initially zero)\n",
    "        decoder_input = torch.zeros(x.size(0), 1, x.size(2)).to(self.device)\n",
    "        outputs = []\n",
    "\n",
    "        # Decoding for the required number of future steps\n",
    "        for _ in range(future_steps):\n",
    "            decoder_out, (h_n, c_n) = self.decoder_lstm(decoder_input, (h_n, c_n))\n",
    "            output = self.mlp(decoder_out[:, -1, :])\n",
    "            outputs.append(output.unsqueeze(1))\n",
    "            decoder_input = output.unsqueeze(1)  # Feeding the output as the next input\n",
    "\n",
    "        return torch.cat(outputs, dim=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2230dc661b094a568c56a9935ca4902f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20562 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shaoze/anaconda3/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([4, 32])) that is different to the input size (torch.Size([4, 20, 32])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (20) must match the size of tensor b (4) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 78\u001b[0m\n\u001b[1;32m     75\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     77\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model(X_batch)\n\u001b[0;32m---> 78\u001b[0m loss \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmean(\u001b[43mloss_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_batch\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misnan(loss):\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoss is NaN\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/nn/modules/loss.py:535\u001b[0m, in \u001b[0;36mMSELoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 535\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmse_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/nn/functional.py:3365\u001b[0m, in \u001b[0;36mmse_loss\u001b[0;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3362\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3363\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3365\u001b[0m expanded_input, expanded_target \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbroadcast_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3366\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_nn\u001b[38;5;241m.\u001b[39mmse_loss(expanded_input, expanded_target, _Reduction\u001b[38;5;241m.\u001b[39mget_enum(reduction))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/functional.py:76\u001b[0m, in \u001b[0;36mbroadcast_tensors\u001b[0;34m(*tensors)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function(tensors):\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(broadcast_tensors, tensors, \u001b[38;5;241m*\u001b[39mtensors)\n\u001b[0;32m---> 76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbroadcast_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (20) must match the size of tensor b (4) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "\n",
    "    \n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# print(f\"Using {device}\")\n",
    "# model = TemporalFusionTransformer(input_size=feature_dim, output_size=feature_dim, hidden_size=64, num_heads=8, dropout=0.1, device=device)\n",
    "\n",
    "# optimizer = optim.AdamW(model.parameters(), lr=1e-7)\n",
    "# loss_fn = nn.MSELoss()\n",
    "\n",
    "# model.to(device)\n",
    "\n",
    "\n",
    "# n_epochs = 10\n",
    "# eval_step = 500\n",
    "# future_steps = 20\n",
    "\n",
    "# # model = TraPredModel(input_size=numeric_df.shape[1], lookback=lookback)\n",
    "\n",
    "# save_every = 10000\n",
    "# train_all = len(train)\n",
    "\n",
    "# loss_all = []\n",
    "\n",
    "# now = datetime.now()\n",
    "# folder_name = now.strftime(\"%b%d_%H-%M-%S\")\n",
    "# os.makedirs(f'../model/{folder_name}', exist_ok=True)\n",
    "\n",
    "\n",
    "# for epoch in range(n_epochs):\n",
    "#     model.train()\n",
    "#     for step, (X_batch, y_batch) in tqdm(enumerate(train), total = train_all):\n",
    "#         X_batch = X_batch.float().to(device)\n",
    "#         y_batch = y_batch.float().to(device)\n",
    "#         optimizer.zero_grad()\n",
    "        \n",
    "#         y_pred = model(X_batch)\n",
    "#         loss = torch.mean(loss_fn(y_pred, y_batch[:, :1, :].squeeze(1)))\n",
    "        \n",
    "#         if torch.isnan(loss):\n",
    "#             print(\"Loss is NaN\")\n",
    "#             continue\n",
    "#         loss_all.append(loss.item())\n",
    "#         loss.backward()\n",
    "#         # Apply gradient clipping\n",
    "#         torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "#         optimizer.step()\n",
    "        \n",
    "#         # Validation\n",
    "#         if (epoch * train_all + step + 1) % save_every == 0:\n",
    "#             print(f\"Saving model at epoch {epoch+1}, step {step+1}\")\n",
    "\n",
    "#             torch.save(model.state_dict(), f\"../model/{folder_name}/model_{epoch+1}_{step+1}.pt\")\n",
    "        \n",
    "#         if (epoch * train_all + step + 1) % eval_step == 0:\n",
    "#             print(f\"Start testing\")\n",
    "#             with torch.no_grad():\n",
    "#                 model.eval()\n",
    "#                 all_test = len(test)\n",
    "#                 test_rmse_all = []\n",
    "#                 for X_test_batch, y_test_batch in tqdm(test):\n",
    "\n",
    "#                     X_test_batch = X_test_batch.float().to(device)\n",
    "#                     y_test_batch = y_test_batch.float().to(device)\n",
    "#                     y_pred = model(X_test_batch)\n",
    "#                     test_rmse = torch.mean(loss_fn(y_pred, y_test_batch[:, :1, :]))\n",
    "#                     test_rmse = torch.sqrt(test_rmse)\n",
    "#                     if not torch.isnan(test_rmse):\n",
    "#                         test_rmse_all.append(test_rmse.item())\n",
    "\n",
    "#                 print(\"Epoch %d: test RMSE %.4f\" % (epoch+1, sum(test_rmse_all)/all_test))\n",
    "            \n",
    "#             model.train()\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TraPredModel(\n",
       "  (TFT): TemporalFusionTransformer(\n",
       "    (multihead_attn): MultiheadAttention(\n",
       "      (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
       "    )\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    (glu): GatedLinearUnit(\n",
       "      (fc): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (gate): Linear(in_features=64, out_features=64, bias=True)\n",
       "    )\n",
       "    (fc1): Linear(in_features=32, out_features=64, bias=True)\n",
       "    (fc2): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (activation): ReLU()\n",
       "  )\n",
       "  (encoder_lstm): LSTM(32, 128, num_layers=20, batch_first=True, dropout=0.1, bidirectional=True)\n",
       "  (decoder_lstm): LSTM(32, 128, num_layers=20, batch_first=True, dropout=0.1, bidirectional=True)\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.2, inplace=False)\n",
       "    (3): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Dropout(p=0.2, inplace=False)\n",
       "    (6): Linear(in_features=256, out_features=32, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using {device}\")\n",
    "\n",
    "model = TraPredModel(input_size=feature_dim, lookback=lookback, \\\n",
    "    hidden_size=128, bidirectional=True, device=device)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-6)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9da4bb3e1b834ad181e2cfaeb9c79d98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20562 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start testing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ad5e4f258c64b4f9d11b95f733468ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2285 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: test RMSE 0.4667\n",
      "Start testing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2802d50de494c3b9b5c4fea015f9e7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2285 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: test RMSE 0.4461\n",
      "Start testing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "129faf770aaf4dc0a9d402d595ac0fd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2285 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: test RMSE 0.4167\n",
      "Start testing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0cc39bffc5449b4ab32910205acf248",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2285 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: test RMSE 0.3530\n",
      "Start testing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "912d3642955f4a7988f9226aab22717c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2285 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: test RMSE 0.2911\n",
      "Start testing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2308de00553943469fab7ef987f7eea6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2285 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: test RMSE 0.2843\n",
      "Start testing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cab6ec231e7a45688d479fc4caba3037",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2285 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: test RMSE 0.2837\n",
      "Start testing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4a2d955a2ca4a0bbbf61bfb2b88cd84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2285 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: test RMSE 0.2835\n",
      "Start testing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc22cb57a3e7468e85db7cf5656e63b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2285 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: test RMSE 0.2840\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 33\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m     32\u001b[0m loss_all\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n\u001b[0;32m---> 33\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Apply gradient clipping\u001b[39;00m\n\u001b[1;32m     35\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), max_norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    524\u001b[0m     )\n\u001b[0;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/autograd/__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/autograd/graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "n_epochs = 10\n",
    "eval_step = 1000\n",
    "future_steps = 20\n",
    "\n",
    "# model = TraPredModel(input_size=numeric_df.shape[1], lookback=lookback)\n",
    "\n",
    "save_every = 10000\n",
    "train_all = len(train)\n",
    "\n",
    "loss_all = []\n",
    "\n",
    "now = datetime.now()\n",
    "folder_name = now.strftime(\"%b%d_%H-%M-%S\")\n",
    "os.makedirs(f'../model/{folder_name}', exist_ok=True)\n",
    "\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    for step, (X_batch, y_batch) in tqdm(enumerate(train), total = train_all):\n",
    "        X_batch = X_batch.float().to(device)\n",
    "        y_batch = y_batch.float().to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        if X_batch.shape[0] != model.batch_size:\n",
    "            continue\n",
    "        y_pred = model(X_batch, future_steps=future_steps)\n",
    "        loss = torch.mean(loss_fn(y_pred[:, :future_steps, :2], y_batch[:, :future_steps, :2].squeeze(1)))\n",
    "        \n",
    "        if torch.isnan(loss):\n",
    "            print(\"Loss is NaN\")\n",
    "            continue\n",
    "        loss_all.append(loss.item())\n",
    "        loss.backward()\n",
    "        # Apply gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Validation\n",
    "        if (epoch * train_all + step + 1) % save_every == 0:\n",
    "            print(f\"Saving model at epoch {epoch+1}, step {step+1}\")\n",
    "\n",
    "            torch.save(model.state_dict(), f\"../model/{folder_name}/model_{epoch+1}_{step+1}.pt\")\n",
    "        \n",
    "        if (epoch * train_all + step + 1) % eval_step == 0:\n",
    "            print(f\"Start testing\")\n",
    "            with torch.no_grad():\n",
    "                model.eval()\n",
    "                all_test = len(test)\n",
    "                test_rmse_all = []\n",
    "                for X_test_batch, y_test_batch in tqdm(test):\n",
    "                    if X_test_batch.shape[0] != model.batch_size:\n",
    "                        continue\n",
    "                    X_test_batch = X_test_batch.float().to(device)\n",
    "                    y_test_batch = y_test_batch.float().to(device)\n",
    "                    y_pred = model(X_test_batch, future_steps=future_steps)\n",
    "                    test_rmse = torch.mean(loss_fn(y_pred[:, :future_steps, :2], y_test_batch[:, :future_steps, :2]))\n",
    "                    test_rmse = torch.sqrt(test_rmse)\n",
    "                    if not torch.isnan(test_rmse):\n",
    "                        test_rmse_all.append(test_rmse.item())\n",
    "\n",
    "                print(\"Epoch %d: test RMSE %.4f\" % (epoch+1, sum(test_rmse_all)/all_test))\n",
    "            \n",
    "            model.train()\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5127, 0.5341],\n",
       "        [0.5126, 0.5259],\n",
       "        [0.5125, 0.5180],\n",
       "        [0.5125, 0.5137],\n",
       "        [0.5125, 0.5128],\n",
       "        [0.5125, 0.5128],\n",
       "        [0.5125, 0.5128],\n",
       "        [0.5125, 0.5128],\n",
       "        [0.5125, 0.5128],\n",
       "        [0.5125, 0.5128],\n",
       "        [0.5125, 0.5128],\n",
       "        [0.5124, 0.5124],\n",
       "        [0.5122, 0.5103],\n",
       "        [0.5120, 0.5074],\n",
       "        [0.5118, 0.5030],\n",
       "        [0.5118, 0.4967],\n",
       "        [0.5119, 0.4895],\n",
       "        [0.5119, 0.4823],\n",
       "        [0.5120, 0.4755],\n",
       "        [0.5120, 0.4693]], device='cuda:0')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_batch[3, :, :2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4858, 0.4016],\n",
       "        [0.5186, 0.3678],\n",
       "        [0.4675, 0.4514],\n",
       "        [0.4267, 0.3913],\n",
       "        [0.4543, 0.3850],\n",
       "        [0.4278, 0.3440],\n",
       "        [0.4942, 0.3227],\n",
       "        [0.3915, 0.3096],\n",
       "        [0.4038, 0.2940],\n",
       "        [0.4094, 0.3385],\n",
       "        [0.4807, 0.3725],\n",
       "        [0.4246, 0.3643],\n",
       "        [0.4803, 0.3855],\n",
       "        [0.5315, 0.4708],\n",
       "        [0.5249, 0.4014],\n",
       "        [0.4629, 0.4613],\n",
       "        [0.4920, 0.5270],\n",
       "        [0.5286, 0.4057],\n",
       "        [0.4967, 0.4431],\n",
       "        [0.4789, 0.3480]], device='cuda:0', grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[3, :, :2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: title={'center': 'Loss'}>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGxCAYAAACwbLZkAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAABi40lEQVR4nO3dd3wU1doH8N+mQ0gCIZBQQghID80gGBAUkVDUK75eRUEQARUpilwbYkWvcFUQ9QqKtGtDVFBREAzSpUlI6IROAiSEBNJIT+b9I2TZMrs7Mzu7s+X3/Xxyr9mdcnZnyTx7znOeoxMEQQARERGRRny0bgARERF5NwYjREREpCkGI0RERKQpBiNERESkKQYjREREpCkGI0RERKQpBiNERESkKQYjREREpCkGI0RERKQpBiNEZJdly5ZBp9Nh7969WjeFiNwUgxEiIiLSFIMRIiIi0hSDESJyuO3bt2PAgAEICQlB3bp10bt3b6xZs8Zom+LiYjz//POIjY1FUFAQwsPD0aNHDyxfvly/zenTp/Hwww+jadOmCAwMRGRkJAYMGIDU1FQnvyIiUpOf1g0gIs+2ZcsWDBw4EF26dMHixYsRGBiI+fPn495778Xy5csxfPhwAMC0adPw1Vdf4Z133kH37t1x7do1HDp0CLm5ufpjDR06FFVVVXjvvffQokUL5OTkYMeOHcjLy9Po1RGRGnSCIAhaN4KI3NeyZcvw+OOP4++//0aPHj3Mnk9ISMDp06dx6tQp1KtXDwBQVVWFbt26IS8vD+np6dDpdOjcuTNuuukm/PTTT6Lnyc3NRUREBObNm4dnn33Woa+JiJyLwzRE5DDXrl3D7t278c9//lMfiACAr68vRo0ahfPnzyMtLQ0A0LNnT/z+++94+eWXsXnzZpSUlBgdKzw8HK1bt8b777+PuXPnIiUlBdXV1U59PUTkGAxGiMhhrl69CkEQ0KRJE7PnmjZtCgD6YZiPP/4YL730En7++Wf0798f4eHhGDZsGE6cOAEA0Ol0+PPPPzFo0CC89957uPnmm9GoUSM888wzKCwsdN6LIiLVMRghIodp0KABfHx8kJmZafbcxYsXAQAREREAgODgYLz11ls4duwYsrKysGDBAuzatQv33nuvfp+YmBgsXrwYWVlZSEtLw3PPPYf58+fjhRdecM4LIiKHYDBCRA4THByMXr16YdWqVUbDLtXV1fj666/RvHlztG3b1my/yMhIjBkzBo888gjS0tJQXFxstk3btm3x6quvonPnzti3b59DXwcRORZn0xCRKjZu3IizZ8+aPT5r1iwMHDgQ/fv3x/PPP4+AgADMnz8fhw4dwvLly6HT6QAAvXr1wj333IMuXbqgQYMGOHr0KL766iskJCSgbt26OHDgACZPnowHH3wQbdq0QUBAADZu3IgDBw7g5ZdfdvKrJSI1MRghIlW89NJLoo+fOXMGGzduxBtvvIExY8aguroaXbt2xerVq3HPPffot7vzzjuxevVqfPjhhyguLkazZs0wevRozJgxAwAQFRWF1q1bY/78+cjIyIBOp0OrVq0wZ84cTJkyxSmvkYgcg1N7iYiISFPMGSEiIiJNMRghIiIiTTEYISIiIk0xGCEiIiJNMRghIiIiTTEYISIiIk25RZ2R6upqXLx4ESEhIfoCSUREROTaBEFAYWEhmjZtCh8fy/0fbhGMXLx4EdHR0Vo3g4iIiBTIyMhA8+bNLT7vFsFISEgIgJoXExoaqnFriIiISIqCggJER0fr7+OWuEUwUjs0ExoaymCEiIjIzdhKsWACKxEREWmKwQgRERFpisEIERERacotckaIiMj7CIKAyspKVFVVad0UssDX1xd+fn52l91gMEJERC6nvLwcmZmZKC4u1ropZEPdunXRpEkTBAQEKD4GgxEiInIp1dXVOHPmDHx9fdG0aVMEBASw4KULEgQB5eXluHz5Ms6cOYM2bdpYLWxmDYMRIiJyKeXl5aiurkZ0dDTq1q2rdXPIijp16sDf3x/nzp1DeXk5goKCFB2HCaxEROSSlH7LJudS4zrxShMREZGmGIwQERGRphiMEBERqeCOO+7A1KlTNTv/mDFjMGzYMJdpjxxMYCUiIvJAq1atgr+/v9bNkIQ9IyooKa/Cwq2ncPpykdZNISIiAgCEh4fbXC3XVTAYUcG8Dcfx7tpjuHPOFq2bQkTkcQRBQHF5pSY/giDIamtlZSUmT56M+vXro2HDhnj11Vf1x/j666/Ro0cPhISEICoqCiNGjEB2drZ+36tXr2LkyJFo1KgR6tSpgzZt2mDp0qX65y9cuIDhw4ejQYMGaNiwIe677z6cPXvWYltMh2latmyJd999F2PHjkVISAhatGiBhQsXGu0j9xxq4TCNCvaeu6p1E4iIPFZJRRU6vr5ek3MfmTkIdQOk3yr/97//Ydy4cdi9ezf27t2LJ598EjExMXjiiSdQXl6Ot99+G+3atUN2djaee+45jBkzBmvXrgUAvPbaazhy5Ah+//13RERE4OTJkygpKQEAFBcXo3///ujbty+2bt0KPz8/vPPOOxg8eDAOHDggufrpnDlz8Pbbb+OVV17Bjz/+iKeffhr9+vVD+/btVTuHEgxGiIiIVBIdHY0PP/wQOp0O7dq1w8GDB/Hhhx/iiSeewNixY/XbtWrVCh9//DF69uyJoqIi1KtXD+np6ejevTt69OgBoKYno9Z3330HHx8fLFq0SF+NdunSpahfvz42b96MxMRESe0bOnQoJk6cCAB46aWX8OGHH2Lz5s1o3769audQgsEIERG5tDr+vjgyc5Bm55bj1ltvNSpdn5CQgDlz5qCqqgoHDhzAm2++idTUVFy5cgXV1dUAgPT0dHTs2BFPP/00HnjgAezbtw+JiYkYNmwYevfuDQBITk7GyZMnzXJASktLcerUKcnt69Kli/6/dTodoqKi9ENFap1DCQYjKpA7pkhERNLpdDpZQyWuqLS0FImJiUhMTMTXX3+NRo0aIT09HYMGDUJ5eTkAYMiQITh37hzWrFmDDRs2YMCAAZg0aRI++OADVFdXIz4+Ht98843ZsRs1aiS5Haaza3Q6nT4oUuscSrj31SUiInIhu3btMvu9TZs2OHbsGHJycjB79mxER0cDAPbu3Wu2f6NGjTBmzBiMGTMGffv2xQsvvIAPPvgAN998M1asWIHGjRsjNDTUIW13xjks4WwaIiIilWRkZGDatGlIS0vD8uXL8cknn+DZZ59FixYtEBAQgE8++QSnT5/G6tWr8fbbbxvt+/rrr+OXX37ByZMncfjwYfz222/o0KEDAGDkyJGIiIjAfffdh23btuHMmTPYsmULnn32WZw/f16VtjvjHJYwGCEiIlLJ6NGjUVJSgp49e2LSpEmYMmUKnnzySTRq1AjLli3DDz/8gI4dO2L27Nn44IMPjPYNCAjA9OnT0aVLF/Tr1w++vr747rvvAAB169bF1q1b0aJFC/zf//0fOnTogLFjx6KkpES1XgxnnMMSneAGCQ8FBQUICwtDfn6+07uOpPi/+X9hX3oeAODs7Lu1bQwRkZsrLS3FmTNnEBsbq3hJenIea9dL6v2bPSMqcPlojoiIyIUxGCEiIiJNMRghIiIiTTEYUYHO9iZERERkAYMRFTBnhIhIfW4wv4KgznViMEJERC6ltkpocXGxxi0hKWqvk2l1VzlYgZWIiFyKr68v6tevr18zpW7dukbrvZBrEAQBxcXFyM7ORv369eHrK28dH0MMRoiIyOVERUUBgD4gIddVv359/fVSisEIERG5HJ1OhyZNmqBx48aoqKjQujlkgb+/v109IrUYjKiAOVZERI7h6+urys2OXBsTWImIiEhTioKR+fPn62vQx8fHY9u2bVa3Lysrw4wZMxATE4PAwEC0bt0aS5YsUdRgIiIi8iyyh2lWrFiBqVOnYv78+ejTpw8+//xzDBkyBEeOHEGLFi1E93nooYdw6dIlLF68GDfddBOys7NRWVlpd+OJiIjI/ckORubOnYtx48Zh/PjxAIB58+Zh/fr1WLBgAWbNmmW2/bp167BlyxacPn0a4eHhAICWLVva12oXw5QRIiIi5WQN05SXlyM5ORmJiYlGjycmJmLHjh2i+6xevRo9evTAe++9h2bNmqFt27Z4/vnnUVJSYvE8ZWVlKCgoMPohIiIizySrZyQnJwdVVVWIjIw0ejwyMhJZWVmi+5w+fRrbt29HUFAQfvrpJ+Tk5GDixIm4cuWKxbyRWbNm4a233pLTNE2xFA8REZFyihJYTSvhCYJgsTpedXU1dDodvvnmG/Ts2RNDhw7F3LlzsWzZMou9I9OnT0d+fr7+JyMjQ0kziYiIyA3I6hmJiIiAr6+vWS9Idna2WW9JrSZNmqBZs2YICwvTP9ahQwcIgoDz58+jTZs2ZvsEBgYiMDBQTtOIiIjITcnqGQkICEB8fDySkpKMHk9KSkLv3r1F9+nTpw8uXryIoqIi/WPHjx+Hj48PmjdvrqDJrocJrERERMrJHqaZNm0aFi1ahCVLluDo0aN47rnnkJ6ejgkTJgCoGWIZPXq0fvsRI0agYcOGePzxx3HkyBFs3boVL7zwAsaOHYs6deqo90qIiIjILcme2jt8+HDk5uZi5syZyMzMRFxcHNauXYuYmBgAQGZmJtLT0/Xb16tXD0lJSZgyZQp69OiBhg0b4qGHHsI777yj3qsgIiIit6UTBNdfWaWgoABhYWHIz89HaGio1s0xc9+nf2F/Rh4A4Ozsu7VtDBERkYuQev/m2jRqcP14joiIyGUxGCEiIiJNMRghIiIiTTEYISIiIk0xGFGDheqzREREZJtXByPV1QJ2nMxBXnG5fQdiAqtkZZVV+PjPEzh0IV/rphARkYvw6mDkx33nMWLRbgz9aJvWTfEai7adwdyk47jnk+1aN4WIiFyEVwcjvx/MBABczC/VuCXe40hmgdZNICIiF+PVwQgRERFpz6uDEbUyPZgxQkREpJxXByOkAUZuRERkgsEIERERacqrgxHOyCUiItKeVwcjREREpD2vDkZUS2BlDwsREZFiXh2MkPMJzGAlIiITXh2MqLWiDJemISIiUs6rgxF+RyciItKeVwcjamHOiHQ61fqjiIjIUzAYIadizggREZny6mBEYJcGKbD1+GWM/9/fuFTABRaJiNTgp3UDiNzN6CV7rv/XISx6rIembSEi8gRe3TPiidYcyMSv+y9q3QyvkF3InhEiIjWwZ0QFrpIHUVJehUnf7gMA3N6uEUKD/DVuERERkW3sGfEg5ZXV+v8uLa/SsCWWMU2HiIhMMRghIiIiTTEYISIiIk0xGPFQHA0hIiJ34dXBiMflL7C4KRERuSGvDkaI7MHYj4hIHQxGrDiZXYS3fj2MbFbaJBGe1rFGRKQVr64zYqs+yD2fbENpRTWOZRZi+ZO3OqlVduDdkYiI3BB7Rqworaip23HgfJ7V7Twu94SIiMiJGIx4EjdIYmDgRkREphiMEBERkaYYjBAREZGmvDoYkTpkYGszVxx6cMU2eRo3GBUjInILXh2MeBqdG9wdXWWFYyIich0MRiSwdY93hyCAiIjIVXl1MOJpQxme9npcHd9uIiJ1eHUwIhVvOurRMdOCiIhMMBhRAXskpGPOCBERmVIUjMyfPx+xsbEICgpCfHw8tm3bZnHbzZs3Q6fTmf0cO3ZMcaNJHHNXiIjIHckORlasWIGpU6dixowZSElJQd++fTFkyBCkp6db3S8tLQ2ZmZn6nzZt2ihutLMpucefv1qM0Uv2YOvxy6q3p1bGlWJkF3IRP60w9iMiUofsYGTu3LkYN24cxo8fjw4dOmDevHmIjo7GggULrO7XuHFjREVF6X98fX0VN1otjhwyeOGHA9h6/DJGL9njkOPnl1Sg73ub0PPffzrk+ERERM4iKxgpLy9HcnIyEhMTjR5PTEzEjh07rO7bvXt3NGnSBAMGDMCmTZusbltWVoaCggKjHy3ZLHom8pijeyzSc4utPs/cDCIicheygpGcnBxUVVUhMjLS6PHIyEhkZWWJ7tOkSRMsXLgQK1euxKpVq9CuXTsMGDAAW7dutXieWbNmISwsTP8THR0tp5leyx2GDZjsS0REpvyU7KQzyZQUBMHssVrt2rVDu3bt9L8nJCQgIyMDH3zwAfr16ye6z/Tp0zFt2jT97wUFBQ4JSDztxuhhL4eIiLyErJ6RiIgI+Pr6mvWCZGdnm/WWWHPrrbfixIkTFp8PDAxEaGio0Y+7USMwuJhXgot5JYr2ZT0Px2PwR0SkDlnBSEBAAOLj45GUlGT0eFJSEnr37i35OCkpKWjSpImcU2vKmbf19NxifLThBLILS9F79kb0nr0RZZVVso/DnBEiInIXsodppk2bhlGjRqFHjx5ISEjAwoULkZ6ejgkTJgCoGWK5cOECvvzySwDAvHnz0LJlS3Tq1Anl5eX4+uuvsXLlSqxcuVLdV6KA1Nu1M2/r9/53O/JLKrDtxI0pwQUllWgUYjz7iMHGDXvPXkFsRDAa1gt06nnZ90REpA7Zwcjw4cORm5uLmTNnIjMzE3FxcVi7di1iYmIAAJmZmUY1R8rLy/H888/jwoULqFOnDjp16oQ1a9Zg6NCh6r0KD5JfUgEA2Hvuqux9vfHmWDt9OsDPB8ffGaJ1c4iISAFFCawTJ07ExIkTRZ9btmyZ0e8vvvgiXnzxRSWncWtqBgZivSCenhOSV1yOs7nF6BZd3+p2m9NqepDKK6ud0CoiInIErk3jIFoPorj7TKG+723CsE//wvYTOVo3hYiIHIzBiImU9Kv45M8TqKiS/k1bcPc7vwsqLK0EAGw4eknjlhARkaMpGqbxGCIxxP3zayrJBgcqe2sWbj2FJ/u1VrTv8UuF4k94UKyj9kthIi8Rkftjz4gFJ7KLFO337lrlqxHnFVdI3tbWTZgr+BIRkbtgMOJCLAYQDCws8vREXiIib+DVwYhDu/jVPLSCYzGNhYiI3IVXByNSueKNXaxHwNL6QK5E7feSOSNERO6PwYgEJRWWy7GnZRXiWJZI4qmCuMD1QwkiIiL1MRixyPgb9wULC9YNmrdVtTNa6tjw5u/+btDZQ0REdmIwIlGljLojykm/89oanvCWAIYJrERE7s+rgxE5+Quycx00iAbcofia2j0dzBkhInJ/Xh2MWOfe37gd2XpBEBT3FLlBvCQdx5CIiFTBYMQBissrFe0n594mNjxx4Hy+ovPKNf5/e9Hr3T9xrUzZ65SDwzBERJ7Pq4MRR2VdvLcuTdF+9t52Ry7arf9vR3ZA/HksG7nXyvUr5notj+rmISLSjlcHI46y/3yeqsfjPY+IiDwZgxGJnBEPyCla5r6Jm+7abiIichSvDkbcYfYJERGRp/PqYITsw8kkRESkBq8ORlxtLRdHtebU5SJ88ucJFKk8+8UZHUsudomMuXTjiIjch5/WDdCSI4dplBxZ6dReQRCsBlYD5mwBAGQWlOLd+zsraJl2OJJGROT5vLpnRA4t80tMk1V3nc5FqoIZO/vOXVXchoLSCieVxHdPJeVVqOD7Q0SkiHf3jDjouI7svL9yrRwPL9ylaF+lw1LZBaXo+e6fuKlxPWyYdrvB8cS3X73/Iq4UlWFMn1hF5zPkDiMhxeWV6Pj6ejQJC8LO6QO0bg4Rkdvx6mDEUQQoC0ikVBvNKSqT1gYVe3I2pWUDAE5mF0na/pnlKQCA29s1RmxEsGrtEKPpMM71kx+6UAAAyMwv1bAxRETui8M0TlB7M7fFUi+ArRtuXnGFtONL2ko9ecXlTj4jERG5I68ORhz1rVoH4yGgf32/HwWlFQ7LO+n+dpK0dimMRtRsNhNSiYjIlFcHI9aY3jSrBQFJRy4hu0B+V/yVa+Xo8uYfmPb9fkVtcYe8CbVcLizD4YvSF/zT9L3xpgtDRORADEYk+iH5PJ74ci9uf3+zzW0tffn/KeWConM7sjfhh70ZkoeR5FLS7Fv+vQF3f7xd+jnY00JE5PYYjFhg+qV3y/UVaksqqpx2Tkcf/9TlIrzw4wE8vvRvq/tpeb9X+y2pqKrGhbwSlY9KRET2YDDiAI6MKew5tulsncuF0mbmqNkWrTsyHl64C31mb8TOU7kat4SIiGp5dTCi9Y3RlKWpvYbtLKtUXljLtGdE6hCH0gDIFTMqkq8Xfvvu73SNW0JERLW8OhhxNVKGaeZvPun4hpiwFLPYimVcLdgjIiLXxGDEAtNeA1dJlNwhcXjBVdpLRERki3cHIzLu2J4wi1Ptl6CsyiwREZEx7w5GHEhJgTO1A57sglJ8uslgWMfkBKYL8FmiatEzk98LSyvw24GLKC6vFN3e3YLAojLx10FERJYxGHEh1tamEQQBF/JKLAYGYsHPY0v/xvvr0yyf0AWGcp5ZnoLJ36bghR8PiD7vbsNNU77dp3UTiIjcDoMRC5TOPHEEQRAw54/j6DN7I/JLxNehmb/5lNljRzMLjH5XPCvGgb0Tm67Xb1lzINNxJ3Gi2tdDRETSMRhxE//dZH0WjdUekOscsTbNyewiRSXypdLpaoqzHb9U6LBzONJ7645h6EfbLA5DERERgxGLTG/Acm/kOgV3fku7/HUyR/axnOFSQSnumrsFPd/9U/R5sSBGbi5NZbWAAXO2IPHDrbimYj6Gmp091i71/M2ncCSzAD8mn1fxjEREnsWrgxFHjbzodDplCawWHndUtVB7X3+aE3oryg2KvF0tLlftuGpeeymXurLKzZJfiIicyKuDEW+jtDdA6qwbb+NmE32IiFyWVwcj1r7RmiZUyunoUNIrAjhjoTznVhrZkpaNTzedVPx+uDpnvapF205jyEfbcOWaej1DRESuxKuDEWsKTfITDHsHfko5j/NXi+06/uGL+XjntyPIL74xO8bitF27zuQ4tmKbjzeexPvr07D1hOvlvDi7V8Oea/jOmqM4mllgXDOGiMiDKApG5s+fj9jYWAQFBSE+Ph7btm2TtN9ff/0FPz8/dOvWTclpNWVYA+S5Fftx2382Wd5Wp7N48xk4dwuOXyrE3R9vx6LtZ/DWr4dtnttRHQv2Hlfq/ln5JfadyAHUfEudVZit3I5FEomIXJnsYGTFihWYOnUqZsyYgZSUFPTt2xdDhgxBerr1VVDz8/MxevRoDBgwQHFj1SYnF0KtG86J7CI8+12q/vcjJrVAHMkdcxzcoQKrh45CERE5jexgZO7cuRg3bhzGjx+PDh06YN68eYiOjsaCBQus7vfUU09hxIgRSEhIUNxYLcm94Vi7h5ZoVHNC7Ru7OwQKlji76UrOt+lYNlZySjAReQFZwUh5eTmSk5ORmJho9HhiYiJ27Nhhcb+lS5fi1KlTeOONNySdp6ysDAUFBUY/jmCt/LopR88oEQQBeRaqq6rF9PWquTZNakYe5v6RhtKKKiVNIxGPL/sb//phv9bNICJyOD85G+fk5KCqqgqRkZFGj0dGRiIrK0t0nxMnTuDll1/Gtm3b4Ocn7XSzZs3CW2+9JadpitgbYPSZvVHhec29tPIAvt/r2G/BJ7LVrQuy+Vi2/r+HffoXAMDf13p8K/cd/3qX9eE/Lcnp7eBIDhGRZYoSWE2niAqCIDpttKqqCiNGjMBbb72Ftm3bSj7+9OnTkZ+fr//JyMhQ0kxVifWiXMiznJgp9+ZjLRBR60Z2tbgCJwwKldmb63Ax37wM/PHsIvsO6oacNVzlzsNiRETWyOoZiYiIgK+vr1kvSHZ2tllvCQAUFhZi7969SElJweTJkwEA1dXVEAQBfn5++OOPP3DnnXea7RcYGIjAwEA5TVPEkxMPLb22XWeuoE1kiM39C0srEBLkr3KryB6e/HklIu8mq2ckICAA8fHxSEpKMno8KSkJvXv3Nts+NDQUBw8eRGpqqv5nwoQJaNeuHVJTU9GrVy/7Wu8lVC0aJuFYaw5kovObf2DehuPqnVeCPAnl3v8+ewW/HbiIjCvFZj1T9tZ+kav2nWSQQERkH1k9IwAwbdo0jBo1Cj169EBCQgIWLlyI9PR0TJgwAUDNEMuFCxfw5ZdfwsfHB3FxcUb7N27cGEFBQWaPk2XOvtfN+PkgAGDehhOYepf04TUASM+9pvi8b6y2XXPlwc92Gv3+6K0t9P/9340nMfuBLorPT0RE2pAdjAwfPhy5ubmYOXMmMjMzERcXh7Vr1yImJgYAkJmZabPmiKuQVeLdzVIQpeQXSH1Fcl75/vP55m0xyLex9p4fuWh91pRYXlJphWMLgWVcKUZIkB/q1w1w6HmIiLyZ7GAEACZOnIiJEyeKPrds2TKr+7755pt48803lZzWbSSfu4oW4XVVO56SvEV7hg7UHna4VFCKyqpq+NmYaWOLreEqtRM8swtK0fe9mkq7Z2ff7bTzan0eIiJn49o0EsmpSQIA6Vecm7/gyuYkHcfwhbsccmzj+ETdu/Whi+a9PGJnKy43r60iCAKyC8xnGxERkTlFPSPeSMthGvcaIBKXfO4qAONv9+m5nhGwzRdZwO6Vnw5i+R7tp6QTEbkD9ox4MUvDHqrO3jE79o3//v1Qpqx9xXJGDB+yNoxxrcy+EvwVVZZzU85fNa83YxqIqPGeKj2EI68nEZEaGIxIdPySesW8ZN8bFNxLsgvFhwhc6bY06/djdh9Dynv5ze5z6PTGenyz+5z+sYJSecFJ+9fW4aQbFnT7audZ9Hr3T5xUufouEZGavDoYcaUbszVKhogqqizvY2sperMeCCd9sz5rY1qwzQRWC4/P+OmQ0f8DwEaDUvZSVFULFuuuSEksFevVcYbXfjmM7MIyvGLw2omIXI1XByNa0TK59WxOMdq++jumrzpgMcSxdtMvsnO4wxprAZQlzszlMT2Ts4NZe+IZDtUQkSvz6mDE9A/0XydznN6GY1mFOGejR0DuTB7A8o1ryV9nAJjnNEj17zVHFO2nBlu9Cw7vfLBwP3eH+7w7tJGIvJdXByOmnF3+vNaLPx6w+ryjvv0Xl5lPSa05n2V7z16165xqvxIlgZpSpuXnZa3ay2iAiMgiBiMu4Fq5+kMfUu59k77dp/p5PVlqRh5+Sb2gdTMUMew1KimvwuzfjyEl3b7AkohILQxG3ICWX6pf+/kQVux1jXoZv+6/aPaYYa/RpYIyh7fh4z9PGP1eWVVtVx7N3KTjGDBns6RFAu1h+Bn6dNNJfLblFO6fv8Oh5yQikorBiAFndvkbcuUe/K92ncOhC9bXjHGW2WJTgQ3eu6Qjl5zXmOsSP9yK/JIKxft//OcJnLp8DUv+Oqteo2w4fonTfInItTAYcQO/H8py+Dkqq6rxU8p5ZLhbGXuN12s5nSNtlWJbybdV1Y5d8I/r2hCRK2M5eBfgiBuF3KTX/+08h7d/q5kpExLEj4UUV65JH1qxXSPFsdGCK/e+ERGxZ8QFuMKNojYQAeA+1eAAh7bVVoDAxRCJiNTBYMSQRl3ZtiqiKqFV/ouzXS5yXNKqlosjOhKHbIjI1Xh1MOIKPRIAcMIBa55MdtFpu2rX29h2wvmF6oiISF1eHYx4slwZ+QwkTqx36dRlaQmrss8lZX0bh5yZiEh7Xh2MGHbD27vEvLdwkc4kl1ZWKV7Z1l6OfO9Lyqvw6aaTOMFpv0SkAa8ORgx1emM9v3leZ+2md9IBQ0qept2r67RuglViPT7zNhzH++vTMPDDrRq0iIi8nVcHI96S5EmuT+tPYkpGnsYtICJv5tXBiKfOlrCXPeXNtVZdzWtKRORuvDoYIc/T971NHpv/o1bviViyrNY9M0Tk3RiMkEe5kFeCNQcz9b+rPZXYYXQ6VFcLmLYiFQs2n9K6NURETuXVwYjpfYrFoDyEwXVdf9jy4nnTVx3A40v3uEzAsut0LlalXMB/1oksCEhE5MG4CAl5HMNcoJ9TLljcbvmeDADAkcwCdGoa5vB2WaMDUFxufUqwa4RMRETq8+6eEa0bQA4ht6OjyiTpddfpXIxesgfnch1T4Exr7AEkIlfDnhHyOHKDTNPg5eGFuwAAW49fVqdBEmkZJDBAISIteXXPiCnWHSFXxk8nEXkqBiPkceQO0wgAKqqqcfoyq8sSEWmBwzQG2FXteM6YuKKkmN3jS//G9pM5+O+I7g5okW387BGRN2PPiAEXmeFJdpLdMyII2H4yBwDw5c5zDmiRbTroJAUkV6+V45WfDmLnqVzHN4qIyEm8OhhxlfoSpC5PuKqWPpuTvt2Hb3en45EvdimuNCuWG8V8KSLSklcHI6bYVe4hZAaZhy8WOKgh8kgJCHYY9IhcuVbuyOYQETkNgxFyqvySCq2bYObVnw9p3QS7bDhyyWZNFE/oLSIiz+XVwQj/QDvfwQv5Dj+H4XVddzjL4eeTShAETPgqGa/+fNDsOaW9cttOXMb4L/fi9vc329c4IiINeXUwQp7JnlQgR43UCQJwIrsI6w5n4etd6aodNyU9T//fT3211+J2Oou/EBFpj8GIAeaMeAZXTUyurFK3XaYvc/3hSygoFR8Gs3VmfvaJSEsMRsjj2HPLd9RNWaezXv9Ep/+fGmLxlI4RAxF5KAYjBk5cYgVOcl2mPT5yYhNbmzLOISIteXcFVpNvn9mFZdq0w0tUVztn+KT2nr3ib/VyM9TW8uU1qBvga/SYGvGApWO45sAVEVEN9oyQ03y7xznBgQDg1OUivLTSfNaKGGf0CogNuxSXV1lsQ3FFFWxRKzUmu7AUuUWsWUJE2vHunhFyqtX7LzrlPIIgICu/VMb2N/7bkZVI5QQPd3+8zWHtMHyFpRVV6PnvPx12LiIiKRT1jMyfPx+xsbEICgpCfHw8tm2z/Idz+/bt6NOnDxo2bIg6deqgffv2+PDDDxU3WE3suvZMKRl5GLlot6J9lSyy5wjncoslbWdv6HSZQ5NE5AJk94ysWLECU6dOxfz589GnTx98/vnnGDJkCI4cOYIWLVqYbR8cHIzJkyejS5cuCA4Oxvbt2/HUU08hODgYTz75pCovQqnCUmVre5AyzsqRXHMg00lnUpet2TJSZtNwxg0RuSPZPSNz587FuHHjMH78eHTo0AHz5s1DdHQ0FixYILp99+7d8cgjj6BTp05o2bIlHn30UQwaNMhqb4qz5BTxWyEZc9QwzZqDmdh4LNvyeRUEEYw7iMhTyApGysvLkZycjMTERKPHExMTsWPHDknHSElJwY4dO3D77bdb3KasrAwFBQVGP0TuLDUjD3OTjqt6TKUJrIaBj4vWhyMiLyMrGMnJyUFVVRUiIyONHo+MjERWlvU1QJo3b47AwED06NEDkyZNwvjx4y1uO2vWLISFhel/oqOj5TSTyCO5amVZIiJ7KUpgNe1SFgTBZjfztm3bsHfvXnz22WeYN28eli9fbnHb6dOnIz8/X/+TkZGhpJlEZAOHeojIFchKYI2IiICvr69ZL0h2drZZb4mp2NhYAEDnzp1x6dIlvPnmm3jkkUdEtw0MDERgYKCcphGpQsubs+0qqRISWC08Xi0Iol8arHW2VFcLePKrvWhWvw7eui/O5rmJiJSS1TMSEBCA+Ph4JCUlGT2elJSE3r17Sz6OIAgoK2PyKFEtJUGQnH1S0vMweskeLN5+Br9KrPdy4EI+NhzNxv92npPfOCIiGWRP7Z02bRpGjRqFHj16ICEhAQsXLkR6ejomTJgAoGaI5cKFC/jyyy8BAJ9++ilatGiB9u3bA6ipO/LBBx9gypQpKr4McgccErBO7vsjN4Vk24kcbDuRI3n7yqpqeScgIlJIdjAyfPhw5ObmYubMmcjMzERcXBzWrl2LmJgYAEBmZibS02+U/a6ursb06dNx5swZ+Pn5oXXr1pg9ezaeeuop9V4FERERuS1F5eAnTpyIiRMnij63bNkyo9+nTJnCXhACAFwrs73eCtlHzd4nzt0hImfhQnnkNAcv5GvdBJu0GkpSa9buaz8fxoYjlyRvX1bJAJGItMdghMgFvL8+TVH1V9PgaeW+8xj/5V7J+/9n3THZ5yQiUhuDESIvtuGolRL1Io/tPp2LJ77ci/NXpS3kR0QkhaKcESJSn6vNNhIbORq+cBcAIL+kAt8/leDcBhGRx2IwQmTAUQvlSaFmtfcnv9yLBnUD1DugiYt5JQ47NhF5HwYjRAaKyyu1boIq/pCRxEpEpDXmjBAZ2Jeep9m5t5+UXpAMAAQNJ9+62pASEbk3BiNELuKzLae0boJkYkNKO0/l4sHPduBYVoHzG0REbo3BCJGb0jK/RcwjX+zC32evYuzSv7VuChG5GQYjRCRJdfWN7hBrwzTZhVwEk4jkYTBC5CbO5V5zynnKK2sWyDMcijmTcw1d3/pD0v4sI09EcjEYIXITRWXGM30ECNA5IJO07au/42yOceDz/vpjKCyTNtNIUHOOMhF5BQYjRGTmi22njX6XE18wFCEiuRiMEJEZewIKdowQkVwMRojclKvNpiEiUorBCJGb+u3gRa2bQESkCgYjRG7CdPjjvXVpmp2biEhNDEaI3MTec1eddq5L+aVWZ8VwiIiI1MSF8ojIzJ/HspFXUqF1M4jIS7BnhIhEJRv0xGi5KB8ReT72jBCRXaqqBXyz+5zWzSAiN8aeESKyy8p95/H6L4e1bgYRuTEGI0Rkk7XZNIcv5DuvIUTkkRiMEBERkaYYjBCRXSwt1icIAhZtO43dp3Od3CIicjcMRohINimLBf9x5BLeWXMUwxfuUnyeHadycNfcLdhz5oriYxCR62MwQuTGLuaVOOU8yQoKrp3Juab/78x8Ze0c8cVunMwuwkOf71S0PxG5BwYjRG5s+Z50p5wn91q5Xfv3/c8mlVpCRJ6IwQiRG3OXUmSV1eq1dF/6VUxfdRBX7QyQiMh1sOgZETmEoxbX+7/5OwAAJeWVmPdwd8echIicij0jRG7MFVbTlZLM6ginDXJSiOTYcSoH/914AtUq9tiRfdgzQkR24Qq+5G5GfLEbABAdXhf3dWumcWsIYM8IERF5qYwrxVo3ga5jMEJEsknpC+FKv0QkFYMRIiIi0hSDESKyi6UEVkcn1zJThchzMBghIiKvZGldJXI+BiNERESkKQYjRGQXfrckInsxGCEiIiJNMRghIiIiTTEYISLZDBP/mANIRPZiMEJEdrE0I0Ewmdu7fE86th6/7IwmEZGbURSMzJ8/H7GxsQgKCkJ8fDy2bdtmcdtVq1Zh4MCBaNSoEUJDQ5GQkID169crbjARuQfTOiPTVx3E6CV7bO53NucasgtLbZ+AXTJEHkN2MLJixQpMnToVM2bMQEpKCvr27YshQ4YgPT1ddPutW7di4MCBWLt2LZKTk9G/f3/ce++9SElJsbvxRKSt4vJKHMsqVO14lwvLcMcHm9Hz33/a3lhmVbXSiiqsP5yFwtIKha3zPoIg4PDFfJSUV2ndFIdgPOs6ZK/aO3fuXIwbNw7jx48HAMybNw/r16/HggULMGvWLLPt582bZ/T7u+++i19++QW//vorunfvLnqOsrIylJWV6X8vKCiQ20wicoJ7P9mOU5evqXa8E9nqBTam3v7tCL7ZnY7bborA1+N7Oew8nmTtwSxM+nYfOjYJxdpn+2rdHPJgsnpGysvLkZycjMTERKPHExMTsWPHDknHqK6uRmFhIcLDwy1uM2vWLISFhel/oqOj5TSTiJxESSBSVFaJd9cexYHzefadXORrbWFpBaqrxXtMVvydAQDYfjLHvvN6kR+Ta96zI5n8QuiqissrLX7m3YmsYCQnJwdVVVWIjIw0ejwyMhJZWVmSjjFnzhxcu3YNDz30kMVtpk+fjvz8fP1PRkaGnGYSkcbOXy22uGbvB+vTsHDrafzjv3+pfs7Ob/6Bhz7fKfo8u+TJ02QXlKLj6+vx8MJdWjfFbooSWE2z5wVBkFTjf/ny5XjzzTexYsUKNG7c2OJ2gYGBCA0NNfohItdi7dvYbf/ZZPG5Y1mO+Zb9S+pFAMDec1dFn9exViypyHS2mBbWHswEAOw5e0XjlthPVjASEREBX19fs16Q7Oxss94SUytWrMC4cePw/fff46677pLfUiJyKY98oezb2OXCMtsbWcCpwc7FheTEfbP7HLrNTLJ/qNFOnnR9ZAUjAQEBiI+PR1JSktHjSUlJ6N27t8X9li9fjjFjxuDbb7/F3XffraylROQyqgUBu89Y/zZWXlkt+rg9Ca9PfLlX8b5a+v1gJvrM3ojUjDytm0IGlPaWzfjpEPJLKjB1Raq6DZLJx3NiEfnDNNOmTcOiRYuwZMkSHD16FM899xzS09MxYcIEADX5HqNHj9Zvv3z5cowePRpz5szBrbfeiqysLGRlZSE/P1+9V0FETnUut9jmNv/ddNKhbZD9d1jDP9xPf7MPF/JKMP5/7hlMkTjNYwEP6hmRPbV3+PDhyM3NxcyZM5GZmYm4uDisXbsWMTExAIDMzEyjmiOff/45KisrMWnSJEyaNEn/+GOPPYZly5bZ/wqIyGsY/u2VO2LvCn+2yys9s14HacMVPtNqkR2MAMDEiRMxceJE0edMA4zNmzcrOQURebnHl1qv1ioIAlYmn8fNMQ0QGxGs2nl/P5gJP18fDOxoPQ9OCe1THslRissrkXzuKnrFNkSAn3NWWvGgjhGuTUNErmlTmnmyquEY/4Hz+fjXD/vR/4PNko4n5Q93fnEFnv5mH574ci/K2IvhUa5cK8eIL3bhp5Tz+sfUvJlP/jYFoxbvwXvrjik+xp4zV2TNNvOkGWIMRojIK0j5w11gUCq+yhGFpNysa8RzbnXA3KQ07DiVi+dW7HfI8TceywYAfLXrnKL9M/NL8NDnOzF4nuW13kxZC6bKKqtw98fb8MpPBxW1x9kYjBCRR1j61xlVj+eIb52FZZVYcyBT9eOSbfkllVo3wap0CUnhpqx9Qjcdy8bhiwX4drf4unGuxquDkYRWDbVuAhGpJKeoXOsmSDLp231aN8ErqVGk7JfUC3jhhxs9K1rX+bB2+ko3KxGvKIHVUyS0boidp3O1bgaR17qQV4Ldp3MRGRqEPjdF2Nzenr/9npTsR9p49rtUm9s483PGnBEiIhX0mb0R077fj5GLdqOssgrV4nXSVCH3z7bgIgkeV6+Z9/hUVwvIKy7HqctF+HTTSRSVKRuCyC0qw6APt+KLradFn3fXAG7ZX2dw7yfbRd87d7XjZA6GfLTNqHCeu14fMQxGiMgldHsrCY8u3m11m+Jyx85wcYHlRoy8t+4Yur+dhJ9TLhjN7pnwdTK6zUzCgDlb8P76NMxae1TR8T/ddApplwrxb4X7y3UyuwgLNp9CiYOv45u/HsHBC/kOL7wnRmlvha2P3ohFu3E0swAjvtilXxfK2jCRq32WbfHqYMTdLhaRJyupsH6D+nX/RcnHElvET8r4vmFviCv8fZi/+RQAYOqKVLR7dR1e/+UQAOCPI5eMtku2sDigLc6evnzX3C34z7pjmJuUZvZcfnEF0rIKVT1fqY3P1Pvrzdvh6orLq9Bt5h9YvP2MaNgjCAJm/X4U3++1vdp9em4xvt2dbnHpBmfy6mCEiNzHlOUpkrf99YB54CJ/mMZ++zPykJVfqsKRany5U9m0UTVcyCvR//f5q8V4eeUBnLikLHjYl55n9tgt727AoHlbcfC885YKccj0bScoKK3E278dwb9+MJ+mvPfcVXy+5TS2ncixeZx+72/CKz8dxKLt4sN0zsRghIg8ztkc+dMkAePeEHtnXxzLKsB9n/6FW2f9addxtHUjhOsze6P+v5/6Khnf/Z2Bf/z3LwDiPVHSjnpD7bfzrSccszKzI8IOV0zZyCuusL2Rid2nrS966QwMRoiIRFRUCXjntyPYpvDmmCLy7d9RTudcQ16x7WRNtRI6D1+sqRJaUlGF/OIK9Hz3T7z4o/xiYoIg4GR2ESqr1BkmyMovxUOf71TlWEopTSp1hWFBLTEYISIS8fWuc1i0/QxGLba+Ro4S1dUC/jqZo1pwUF5ZjW4zkwAA6w5lod97m7DfYNYFAHy+5RS6v52EZXYWhzNt8w/JGcgpKsP3e8+bbSsIAmb/fgw/p1wwerz2hv3d3xm4a+4WTP5W+hCcNW+sPoQ9Z7T/ll+rQkKQ9c3uc1hwPTdIDUp69FwhDmIwQkQeR3RaroRvrIZ7pV9RNtQjxcp95zFy0W4M/mir6see8HUy0q8UY9z/9ho9Puv3mjVT3vz1iF3HzyowzoGxlhj818lcfLblFKauSDXe5/rF+HxLzU143eEsi8eorKrGwq2nJOWSXFUwROEI5ZXVaPnyGrSZ8btZIAbUJNauTD6PorJKzPjpEP6z7hjOX3Xc580deHXRMyLyTLa+HKZlFSIzvwS3t20ku4pmZn4JokKD7Kq+ue5Qzc33UkGZ4mPYUmZjJolSW48bD1uJvQvHLxUir7gCVyQMHZl6f30aBnaMRNvIEADA8r8z8O7amkDq7Oy7re9s7bo78eu/4WJ8U1ekYlj3ZkbPt39tHQBg5m83AkOltWJqXblWjlX7ziM40D1v617dM+IqRY2IyLkGzduKMUv/Ruz0tUg+d6Nb37CLWyyg+WLraSTM2og5fxw3ey6/pAIv/XgAuyRUdTaMY0orqrB6/0VJOR9y2PrrVlpRhW8UrFtS28NSSywmS/xwKx76fKdZ4HJjJ+vnGPHFjXozxzKlr2JrqvY9KC6vxP7zeeLbqJysoQNQIHEdnPwS9RZmfPHHA3hnzVFMX2W+MN6nm07qZ0MVlFYgw4G9fkp5dTBCRJ7BnhvKE18mS962tjiYWDGt2b8fw4q9GXh44S6bx9lwNFv/3++sOYJnlqdg9BL1c1Os+WTjCYvP7c/Iw5mca2aBxqnLRbLO8WOyeR4JUHPD/mjDCZy1sDhcTtGNHiOxK1taUSWeb2MhyPnngp04f7VE9LkDTpxKbE21wWdYSULvprRsi8+9vz4NDy7YAQC4eWYS+r63yeWGhRiMEJHbG2+SHyEnNLH0jVRuz+m53Guytq/1c0pNTRQ1boqGxc9sBWg7Tpn34OzPyMPq/Rdx36d/of8Hm82eHy2SzKt0sOrDDea9S4YuF4oPYZ3NuYb2r61D97eTkFtkso2Fl3zESu9KYan9q/nmG+SqKB2+M4w/lu04K3t/Xx/r5714vd5N7QJ6e88qK5TnKAxGiMjt/XnM+Fuh4Y1MEAT8cThL0k3Hno5yZ60T8vdZy7NFHrj+7VcK0+ZWVFXjvk//wjMGxeW2pBkPsxgWPrOHlPfql9SaxE/DTbccv4w7DIKk5HNXsSktG4cuOKZ3Y9qKVDz11V6bgd2/fki1+nxpRRWSz11FdbVgMfg17BnZKqFgmRk7PrxqD1Up4Z6ZLipxgfefiBzA8Ga3/vAlTPha2lCM4R9lwzVGhn60DdOHtrd+TpVLYE0zmYFS6+mv90na/5rM9V/EpqGWSxgu8LHxjbyWWS+GRKUVN9qwySToPJ1zDbN/N0huVfESlFZUYdX1mTDnr5YgOryu2TaFpZXYdTrXaNhNzPj/7cX2kzl4eUh7fGshT8ewcJyj4lqlaxg5g1cHI0Tk+WzVnSgsvdHFblSB1eCr5pHMApv1RpQXu7pxnjUHMuHrA7yx+rDFmTZyznP6chFaNapnlINx4zjGB1IaTEndK/6dDYrOZS1PxWy9Igd9wbTUm5FVUCopR2j7yZqejtkmyb9G5zAMhBVcCinDip9bWJ3ZFXCYhog8juHfclt/2KsF4ExOTb6HWveylHRl4/GTvt2HCV/vszrlV2JHBADgzjlbANSUbzelZSlzKTfb2mDJ8JqYDifUVoK1xtmLwOlgXotFCnt7Rty9p9+rgxFnjfESkXYsJUIa+jG5ZoXTauOuEcXuny89d0MuHwV/uMRW9TU9jNK/h84se6/Ez6nmRccMifUobD+Rg+7XK9rWbCPP4u3yq9wa9owculggOyFabhtdbXqvVwcj7h5JEpG42lVhS8pranjYUvu3wPBvwiqRypnWmA57OGpFWCXBiCMZvk9SEyGlvISLeSUoqzTOe7F29KvXyrFHJLm3SOJsmfWHs/D93zVB6aOLd6NEadE4hZfH8ONyubAMt7+/Wdb+cpNQ5yTdmM207YR6SxMo5dXBCBF5pqPXp3LK7S6vlvEHvapawJmca/qbgOk96NWfD0k6jtxEUzVmtByRMLyhxIcbTqi26N3i7Wdw2382GQ1LWbs+/7aQnGnrip7JuYb03GI89VUyXlx5AOkitU+cMdtEzmdPfH/7zv+gxgsMMoGViDyW1JvI5rTLmHJnG1m9pU99tRcbjmbjnWFxePTWGLca9h368Tazx9S433785wnUr+NvczupCayXC8tQbFAm3doN94KFoma2PgOv/3IYwGH977nXzIf1nNGJXu2gnjSpTmbLK2inNq/uGeEoDREBNbNlXvhxv6x9aqdz/ndjTTVWN4pFHMrajJFacoawDHuOLFV0BWpKvouRG2RpFRP8kmp7ONGTeXUwQkSe61hWARbKmMr424FMRV3ludfK8Ommk0jLKpS9rzNIyZkB1FurS0ptkp0S1u8RPbaVmTH7LVSwlfu63hUZ7hGEmmnSUigNSrNFEq33nLnisNwjV8NhGiLySIPnmQ9F2KJkqKKiSsD769Pk7+gkhhVVnUGnc53JAWUV1bLbIjbz6OGFO5FT5PwEz4c+34mXh7THhNtbO/3czsaeESKi61zkHqoJtQIIVwlEAGDlvvOqXFMtApFaX+08h8x8dcrwuzKvDkZaiJT3JSLvtWqf5ZwET+dCMYSqXCk4UuJCXgkSZm3UuhkO59XByP3dmynaz09OCUQichtf7jyndRNIZfZOmZWrQIVVgL2RVwcjvj463N62kez96te1PXXNG7VqFKx1ExxmUn/PH7Ml7+YKK7eS9/LqYIRIqvp1ArRuAhEpUKa0kio5ldcHI/wuoCK+mURuq6jMM4cXlvx1VusmkAReH4wQERHw9Nf7tG6CQ3hqkOVpvD4YYSqqijz4zXSnUt9ESqRm5GndBPJiXh+McGSBpGBuHxGR43h9MOIObm0VrnUTXE5MQ9aIISLyFAxG3MC421pp3QRpnNh7MH/kzc47mQVD4qK0bgIRkUdgMELqcWJeRaemYc47mQUxDT23rgoRkTMxGFEgJIhFz4hJrUREamEwosCCR29GhyahTjuf21RGdJNmquX/FC4nQERExhQFI/Pnz0dsbCyCgoIQHx+PbdssL9WdmZmJESNGoF27dvDx8cHUqVOVttVltI8Kxe/P9tW6Ga5Hw56CpY/f4rBj39KyAQSRSKtekJ/DzklE5E1kByMrVqzA1KlTMWPGDKSkpKBv374YMmQI0tPTRbcvKytDo0aNMGPGDHTt2tXuBpN2GoUEat0EUXd3aYKEVg0lb//OsDhZx+8WXV9mi6S7o538tZGIiDyN7GBk7ty5GDduHMaPH48OHTpg3rx5iI6OxoIFC0S3b9myJT766COMHj0aYWHaJx2acpshEBew6unemDawLSbe4dhF4zo1lTcE5qPTOTR/I6yOeI6QToWuoBbhnKJMRK7hQl6JZueWFYyUl5cjOTkZiYmJRo8nJiZix44dqjWqrKwMBQUFRj9ai49pAACIa+a8XJFarhIuRYfXxTMD2mB0QkuHnkduYKHV6JCPCidmDiwRuYrjlwo1O7esYCQnJwdVVVWIjIw0ejwyMhJZWVmqNWrWrFkICwvT/0RHR6t2bFM6iXe+z0fF48XB7bBkjONyE9xFVFgQDr81yOzxR25pYfex37i3o+x9dDp5vRT1AlXK9WAkQUSkCkUJrKY3cEEQJN/UpZg+fTry8/P1PxkZGaod25TUYZqIeoGYeMdNaBwS5LC2yKVFL02tYJEbet+2EXYfV8mnSO4+nJJLRCRCw254WV8RIyIi4Ovra9YLkp2dbdZbYo/AwEAEBrpmsqQWLMVL7aNCceiC9kNYWtM5OGfEEh8VTqpmEE9E5K5k9YwEBAQgPj4eSUlJRo8nJSWhd+/eqjaM1DX3Ic+dyST3dt4uKkST8xIRkTjZwzTTpk3DokWLsGTJEhw9ehTPPfcc0tPTMWHCBAA1QyyjR4822ic1NRWpqakoKirC5cuXkZqaiiNHjqjzCkiSAe3V67lyJDm9hHd3bgIAGHtbrKzAoH2UdsNb9ogOr4Mgf3XrFH72aLyqxyMi9yVWT8lZZGfyDR8+HLm5uZg5cyYyMzMRFxeHtWvXIiYmBkBNkTPTmiPdu3fX/3dycjK+/fZbxMTE4OzZs/a13sH8fXWoqHL+xakX6Ieiskp1D+pGX+OlJqP+d0R3zC7rjJAgf1RWVcs6R6/YcOw+c0XStsGBfqgQOb6zh1jqBfrj38M6Y/SSPaods2l918mBIiJtVcv7M6oqRdMKJk6ciIkTJ4o+t2zZMrPH3LWWR6uIekjTcKoTADSo6w81sopM75vto0JwLEvb1yZGzu1dp9Pp1wlyZGDwSM8W+HLnWfPzO+yM4hxxPjf9p0lEDqDlnwOvX5vmvm6W1xeRe39rVr+Ona0Ra4NjbnkN6gaofkx3urHJaWqQv6/o447uGPn+qQSHn9ONLhkROVi1hn/EvT4YeeDmZqgbIH6zkXpd7uvWFEdnDsYnI7rb3lhF9t6XBrRvrEo71KZk3FKLUSg1KrBaCy5MexTl1lORwl17LYlIfVr+PfD6YESn0+mrqyrlq9OhToCvarcJ0+Oo8fkwOyYEzB3ezf4DuyuZ76loSooqFVjdKJmHiDxatYbfTbw+GAEs3+zDgyUOZUi4n7x6dwfJ7WkTWU/OoRWztOaKUmoNISi5QTt6yKRKJLNLixIhHKYhIkfRsqOUwYgV7/2zC3rGhmPR6B7WN5RwAf/RtSnOzBqK35/ti7F9Ys2e79o8DGueuQ0PxjfHf0fcbHToZg1u5KL0UNiLYyn35N37O6N1o2AM7yG/5P5X43oiOvxG29ypx1/uUJBYz4gn9GlwmIaIatUNFE9ZcAYGI1ZEh9fF908l4K6O6tTo0Ol06NAkFH6+4rexTk3D8P6DXdHUJBG2S/P6+M8DnfHZo/Ho3FzZysc6AAMNXkftPWhErxb48193oHkD+cm3fds0woonbyRZapn8JBZs/TjBPAFUKfGeEeNzGgZmUsnp6ajJGVEXYxEiqhXoq11IwGBERY6Y+VJ7xOG3tMDguCi7jrVw1I0CV60b17OypXSGL7lRiGuV8G8QHIBlj0tf2LBrdH2Lz1WKDKaaXm2l+R8BFv4AaBUn9GvbSKMzE5GWmDOiMXurzqly/RQEMrK/Vet0GNO7Jer4+2L6kPZGz6vxGoL8fbHj5TsxtLN9QZMzcjHG920la/seLc2Hx0zbqfRzNPuBzpK200H9rhGxFjdjITQir8SpvS7o81GuUSZb7aTQN//RCUffHqwvFmYvw8XiBAFoWr8OGtWzr4dErX8P1t66QZ2isP2l/ujZMlzS9v3bmU+DVmVqL4CGMt4v9af2qno4InJjVQxGXE9kqPRvh/bcHnyu79wrNtz6hjKFBikqriub4Wt3t2TI5g3qmgV7cc3E160RG4IzfKi9HYvv2bOvvbT8JkREroV1RlyQnABD7uVrbJBbsen5O/D6PR3x3F1tpZ1L4sl+mNDbag6EagzeKFe7r/n52P54mzY5KlRZFV17FpyLDA3Cn/+6XfH+RGTsrg7usTCoq9FybRoGI3DOTdTwFKMSYvDwLdH4fFQ8YhoGY+xtsahjoQqsUu2iQvDjhAT4+egQHOCLQD/rl1pp705EcCDaR4WgQ5NQq3VLIkNlDEWoMBJxd5cmiA6v49A1a0wPbU99lNaNzBOKI0yGb2ryfmSfwipXCyCdScnsJ3IPrpZM7y607Cl1Tl++l5B6nwj088XsB7o4tC0A4O/rg0NvDYJOB/j4OOam7OOjw9pn+ur/GxAf0tjyQn+0f22dQ9og5tPrtVpsdjuaPC31bRJLAFZUxt5CdPHeA11wk0oznqzRcslwrb3/z654eOEurZtBDlDHwnpSZB1n02gsxEH5Ff4G9UQcEQoYfhMPttCzEuTvi0A/2/8w7fkM+vjorAY7/r46i4vN/TKpD36bcpsdZ1eX6TpF795vPtOlVUQwnrq9tSrJpIM6mXcn1w3wxUO3iBehc06dEU8o52bbra0aat0EcpCoMPaMKMGcEY29cW8ndIuuj3ky12qpLSL2eJ+WZs8dfmsQdrw8QP+78ktsfGO4t2tTxUeSa/FjNirPqqBrdH3ENTMu5NYkTL2ppXKHaQyv06T+rTGiVwuRg9rXptWT++DwW4OwYVo/xMeYJy4vsJB/ogPgZ6Mo0f/G9pTdHtNg3FYXd+/WvIkrsdBFZuh5A9PCkZ7qrg7qLnbKnhGNNa1fBz9P6oNh3ZvJ2m/hqHjsfyMRXZrXN3suONAPATbyNKQx/nTYu6ifHDENg1U5jtwehLeHxWGInQXepFIyTCE2+0UQBMmvUwcdggP9cFNj+bNoukfXt5qYfLvMgmViX4Se6tcK93RpYnGfbs5IjPZA0eF1LT63bmpfJ7bE8w2Ja+KUYU5nmv1/5r20lnqcxQT4+WDUrTFWt2GdERck5Qu1TqdTfbE5uWqrZY608SFTQk7SqTVyb/iNQ4Is9g5YIzYt19LwlSWWqqECN4KQuQ91k3VM1ehqhsO+Gd9L9Gkln0WxaxMc6Ge0PpJIM0gBHytvXPso8Snl3uj1ezrafQxfHx02THOtGWotrASjU+9qY3N/sb+icnp+ZwztgI5NrX/O2kZqV2aAwYgFrrNyrPWDfvbozfhqXE+8MKid6mcxLIymVmBijzbXv+kM7iTeaxIZYj68Y6snyfCLgE4H/Cvxxvto+hlYN7Ufzs6+W/9txPB663Q6oxu7tcBA6efkhUTr13jFU7fKPqY3z6ZR6j8SK+aa8oQgrmMTxwdNaubw3XZThGrHspe1L2UT77jJ9v4O/rcaFRqEdhrWPGIw4ubqBvihb5tG8LdzgSNLn/OVTycgoVVDRbkIaosMDULaO4Ox4FHxb+3/vr8z+rdrZLQejdyckSiV8lXsvR6m/tG1KW5rY/0Pq5Jv18Emq3TWC3T8BDtnnMORht8ikkckgQ5A/bra9qRa00XCIpyW/k6o+WVFzXvuV+Mc+3fr4Vui8dHD3SRtay2Y8JUwjc80SHswvrmk80ql9cw6BiMWNAhW94+G0qjW2r3UGd+04mPCsfzJW1XtRlZacVSnq5kWbSnAiAoLwtLHe+IOkdLtjiYnZ0SJYBk38PDgAMnb3tzCuOfo2yfEh4AMOfJ1ehrD4ls6HbDnlbvwzrA4vGwyNdzQsG7OS1KvVcff8r8rKawNQWnJEXWGDIOA2Q90kTy0Ye0e4KMDkp7rhy+tfOnrYNIrdUvLcLN/iY8lxGBQp0jRWYC22qA1BiMmlo65BR893A3NG1ge33NVT9/RGgAwtk+sxi0xZvoPoHdrV+o6Vc41//wCm/51h/6/rf0tbhoWBJ3OOLQQS8YmZfx8dEZrXOl0OgT4+eDRW2Mw4fbWaGqhF06LG7sAAdUSplJYarOqLXbiDfOdYXFGv/9TQm+DOhMTjOl0OrSJDLG6YnZTkwUsBQhm/75fHNwen4/qIToLUKfTvvfDGgYjJvq3b4z7usmbVSOFM/6+vDioHf54rh9evbuD409mh7G3tcSoW2NUSVQjc2EGQwHWvgnVPqXWoomOsuJJ+bkwgLQpyGuf6Yu7O9+YOXS3lVlEQM1wmVQCarrfB3aMRM/YcMSazE6ztHK03G/ztUUHTRnekJoZTHXt3qK+2b89QQCqrAQjqyf3wf/G9kSzBuJTZqW0OTw4QFKvqD03zK/H9cKu6QNsb3jdoyaJ/zPv62Rx27F9YtHnpoZ4aUh7hNXxR5+bbH++DGevvDi4HTo3Mx8Kk3q56wb4Yc8rBuUiTN6md+/vbLUH1ddHh8YieXWuwr0Hb92IM7rHdDqdptnQltT+Y0t+9S5cLa5A8wZ18bbJNxKt2FPkx3RPV/zWMbZPLJb8dcbqNgtHx+Nf3+/Hi4PtS4J2lF6tGuL1ezriy51ncTa32Oi5iHoByCkqF91v3G2xuK1NBN5bl2bx2B2bhuLd+ztjzcFMAMDLg9tjzYFMi9v3tZC30zA4ALnXjNtRO03yi9GOrdfTqpH4FPx37++Mb3enAzC+4T19e2skdorCzN+O6B8TYH1aZ22P2cajl0Sft7UM1O5XBqBB3QCMWbrH+oaw72+lrbwqW6ytZ/X6vTcCuL2v3gU/CXkeM+7ugJn3dcLlojI0DgnCne0bY39GPj7ccBzJ564CAM7Multy+xobLOAqwLhHyrQ35J/xzfFj8nkANZ+R/+ve3OayIFpy3Za5IXceSzetPOoIDesFutzcf8O/e6ZXT63erHeGxWHLC3fYdYy2kcret2HdbX+T79Q0DOum9sOd7aUtLmbtfZE720Jq+f2xt8Vi8ZgbicnjbqsZipw/Ml6fPGm62KROJ22WgqFAPx/snH4nHurRHG8Pi8Ovk42rA1vqAfh5Uh+zx3wVfoActHKDnui9XgBaSqgrZPj65zzYVf/f1qbEAzX1MAL8fDBLpFaGFGoX97JE6nvv7+tj8bNwdOZgHHgzEamvD0TQ9Vyc2h6JkCB/3NYmQpVr3KV5mNUeqcn9b3z21z7TF3UCfK1Wym6n8fRyBiNO4qL5XXoje8WoVlnz9nbG455q9Qo5ctE7JcyCF6NHbrzoR2+NQUzDYHRvUR/N6teRNX3ul0l98MKgdmbdydLbaPk9U3pdRie0tDh1+XORKqOGwyA1bbrhtyl9FSVsTh/SHkdnDkbP2HD8+a87sGFaPzwroVaDGNMerSZhdfDeP7ti1K0x6Gwyw6R7i/qixwj0v/Gn9KOHuyGiXgC+tDGTw9LHWezxhFYN9QGYKUEA9r02UPLsCrHrLkDA28Pi8MDNzbHy6d6SjnOfwXWzteRE7WuKaRiM4T3Elzq40RZzT1gY0rKHab4IoOxvjGG119PvDkWdAF+EBvmjfl3pieS2TLi9tf6/t73YHz9MSECnptZnPxm+FCn/1j940PHrpVnDYERFba5/exUrp614No2151S8N9cJ8MW3Tygbmzd1R9tG+E7hOL8h0yDe2aGIrX/scq16uje2vthf1rTfrtH1Man/TapPFbZHo5BA7HttoNnjcc1CRauMfjrScgG1jk1DMe/h7rLboNPp9Ctd17NQzdZaIGZYIM9wO2s3ozG9W4qurgzUFOp7ZkAbvDCoHe7r1gx/z7jLZqK2pb8JYu0e0asFJt7R2uzx3q0bIsjfB+HBAXj/wa6IjRDv3TB+WeYnHnVrSzQKCcSch7pKrvLs66ND+6gQRIYGItbCUJGY//yziz6HpY6/r1kejtj7Ys9Cn2LDKWdn3y0a4Cs5S1gdfyQ91w9bX+ivyoKktUGlYX6NYfAfHV4Xt7SsWUZCydmWPX4L6vj74uNHjP/daZ1P4jp/4TxAkL8vjr09GDtevhOA6/eGOIpOp1NlEbItL/THv++/8e3FWQub/fFcP8x5sKvoInaWmP/9NL/4Op1OUj0BOfpf74USXUMHQJC/5X/i9uS4mL6O+nX98Z/rK1H/OCFB/3jo9doIDQ2mG8+6XjRs2sAbwyq1Zewt5WQANUWZail5G1NfvxFAxRtMaQ6t44fBnaIwsGMkIupZ/jbboYn1Hq1pA9ti0vWucSnfsE0TRmuvVW8JiZG1vhnfy+hcUt6X2pv9Bw92xbSBbfHVuJ5mU40lTfHW6bDmmb7Y/tKdNvMnTJ/9enwv3Nu1KX6a1BsfPdwNx98ZcqN9kv41Sbfmmb4Y2auFxZ4lo/MoPFGbyBC0aCh9BmaTMMtr57xzfxy+GtfTaOjPUruk1kUy3P+Odo1x+K1BspKxnYEJrCozXCvAcMxY7ZuQO1G6nHd0eF2M7BWDfm0aYcepHNzfXd0iP4D4t7C2kSGSEoFNbzjdousj/UptgqVzklnf+kccJheVmRWsemFQO1wuLEMbJyU0p7w2UP9+9GgZjsf7tMT+jDx892RNYGL4Xt3TpSnuaNfYqPjZ4sd64GJeKRqHBqL9a+tEzxEc6IcdL98JP1+dxZv9mVlDETt9bc0v1zc5/NYglFdWW+w21+l0+EzCInaGyYNqKK+qNvr97xl34eq1CgQFSP+OaPo+WPo7I/Y5tzaNtXfrCKx8OgFjlvyNVwxm55n2+vr66OArIVQwbWdsRDA+MfhmHuB343mxttrzxa5dVAj+fX9nLNx6SlY7V0/ug9WpF7Fou/UEcCVev7cjqqoFPNzTfMgq0M8XfdtIG+qe1P8mZOaXmg2FAkBEvRvXyrRnVY0eHLUxGHGg4EA/PHV7K1RWCTZXQvVES8b0wNu/HcWch7ra3tiK6PC6GB6urOqlLWqGDG/fF4fo8Dq4v3szPLxwl4pHtszPVyfarT6pv+3EzQ8VrLEzOkE8d8X0ZvPGvZanSALmVVj9fH303yybN6iD81dLRPeztRqrWJASHOiHYDv++S1+rAcOXyzAHTIXIbSlwiQYCQny10+zbla/Di7k3XgPpN6Mh3ZuguOXTiDGyrd0qZ/5+Jhw7H8j0ejGNbZPLI5fKsQgC0syAEBMw7oYf1sserVqiMQPtwKQ17MhnlNl/81T7lB5m8YhFqcy2yuiXqDV4UupggP98KGF1eaDA/2w+fk7agJGFww+TDEYcbDpQ1y75ocj3dk+UvIMDVdgb4JsWF1/vDCotrvbtf/xn/j3EEV5KDPvUzYle3BcJL7elW5xGqohtYY3rR2mlYXcDzEDOkRiQAf1P8eJHaMwb8MJNBe54fVqFY5V+y7ofxcEaUHEpP43oW1kCHrFhhs9rjRnzfQbdJ0AX3xkI8endaN6GJXQEukG07ClXNO9r96FotJK0W2dOeR9ZOYgVFQJqBPg69IVS6VoaSGHyBUxZ8TFeWveibM8fIv1zH5rDP9ONzP7xq78r5i11T0B4+E/pYmtSvazp0z5jKEd8f4/u+D7pxIkbesoP05IwNS72mCkhRwbqX6bcpvtjWzo2DQU217sL7q6rFgSq+mNcZ7IN2J/Xx8M7dwEDesZdwUZ1tNx9A22e3R9s8eklD2IqBeIlhHBiFR5OKzW/d1rilne2d54mrBpMFg3wE+fMOrmsYhbYc+IW2OkYq+Hb4nG9FUHFe2r0+lwdOZgVFZXG+UKKfXblNuQU1RmcUZErToBvnhhUDuUVVY7bfhvw7R+ZjNWOjcLw8EL+VZLWNeqE+CLB21M6aw1OM7yEIAcYj1dPVqGo0fLcJGt5YlrFobBnaKw7nCWXccRm30EmH8JMf39gwe7Ylh36ZWiBaP/Vv8WaxjgPHm7fdNwg/x9sffVu+Cr06H720kAjEvkP9E3FusPX9LnZz11eyvooLP5uWkcGoRjbw82K/w1tHMTLNx6WnQfe4oiuoN2kSFIu1Ro8wuQMzAYcVH92jbC1uOXjcoJm7KW+a/Une0bY+OxbNGEKE9gWovB3qGZmuml6hSMixMpFW2JlJwQNfmKVKZcMuYW/Lr/Iv7vZvWXT6hlaS0Ua/7RtSnSsgqR4ODZV+P6xmLd4SwM7Kj+EI7Yp9KwMKHcf5+G91RH3F8ND1lbc8Twn5bcf2YRJj07prt/OLwbHliwA0BNgvxUk4J3lqjxpUELPWPtD6DFLH38FizefgZjerd0yPHlYDDiohaOisehC/no3sI8OXH+yJux5mCmUSEctXz8SHdsTstGfw1WvnWG2umnhib1b41PN53CDBdf00epAF8fs5kbcondSxqFBGKshOmSSsx5sCveXXtUUZLfx490r1lF2cFjnLe0DMe+1waivoUCcPYwHWYBahISlz5+C3SAvsaKLXe0a4TNaZcxKiEG76+3XBbf1ZkW8JJaC8VeWid+7nllADKuFjvs9TatXwevucgaYQxGXFSQv6/F7uShnZtgqIN6LuoF+uGeLq41/1wt/r460SltLwxqj2cGtLFZRdJd/fbMbfhy51kcv1SEPWeuSN4vwM8H5ZX2BTFKPRDfHP93czPFAYWzqvWGB6vfOwnUBMinLhch6UjNWjBdr68NI/dLwmePxuPwxQJ0j66vD0YcsepsVKhjhwsbqFjNVI4He0Tjq13nMKC9Nl/OGocGqT6l3FUxGCGvYS2JzlMDEaCmbso7wzpjyvIUWfttf7E/er77JwBtEqldrfy/M4UE+eOL0T1w5Vo58orLLeaW2BLk72v2rdoRwcgzA9rgUkGZUYl4NXz26M24Wlwh+vr7tonAthM5eOBm9esP1aoX6IeN/7rDYcenGxiMkPdw4r2tU9MwbDl+2XkndADDb/2mdUHIOcKDA1TvfWnlgOmeIUH+ZuXFDSnNUxkcZ94DXFuQ8H+P90RJRRWC7fxsJnaMxMKtpx2Sg0fS8S8MkQN88GBXfLrpJB7p6ZhibUo0rS+vu9fP1weLRvdAWWW1aA4DuZfVk/sg91o5YiSszquG5g3qIKFVQ9QN8JWc42LNL5P6YM+ZK3jgehK6j4/O7kAEqJlhtX5qP9n/PkhdDEbIpbhimWIlGoUE4s1/WK9C6mxT7myD3KJy3NNFer7RXQ6YKULa6HI978RZdDodlquwYGatrtH10VWkhoka5KykTY7BYIRcwtg+sdhyPNuh478fPGhfWXp3Vy/Qz+vfAyJyTTrBDaq6FBQUICwsDPn5+QgNDbW9A5GBvWev4PzVEllFooiIyH5S79/sGSGPV1N1U+tWEBGRJYrmeM2fPx+xsbEICgpCfHw8tm3bZnX7LVu2ID4+HkFBQWjVqhU+++wzRY0lIiIizyM7GFmxYgWmTp2KGTNmICUlBX379sWQIUOQnp4uuv2ZM2cwdOhQ9O3bFykpKXjllVfwzDPPYOXKlXY3noiIiNyf7JyRXr164eabb8aCBQv0j3Xo0AHDhg3DrFmzzLZ/6aWXsHr1ahw9elT/2IQJE7B//37s3LlT0jmZM0JEROR+pN6/ZfWMlJeXIzk5GYmJiUaPJyYmYseOHaL77Ny502z7QYMGYe/evaioqBDdp6ysDAUFBUY/RERE5JlkBSM5OTmoqqpCZKRx7YHIyEhkZYkvpZ2VlSW6fWVlJXJyckT3mTVrFsLCwvQ/0dHSlh4nIiIi96MogdV0zQhbK2SKbS/2eK3p06cjPz9f/5ORkaGkmUREROQGZE3tjYiIgK+vr1kvSHZ2tlnvR62oqCjR7f38/NCwYUPRfQIDAxEYyPLTRERE3kBWz0hAQADi4+ORlJRk9HhSUhJ69+4tuk9CQoLZ9n/88Qd69OgBf39/mc0lIiIiTyN7mGbatGlYtGgRlixZgqNHj+K5555Deno6JkyYAKBmiGX06NH67SdMmIBz585h2rRpOHr0KJYsWYLFixfj+eefV+9VEBERkduSXYF1+PDhyM3NxcyZM5GZmYm4uDisXbsWMTExAIDMzEyjmiOxsbFYu3YtnnvuOXz66ado2rQpPv74YzzwwAPqvQoiIiJyW1ybhoiIiBzCIXVGiIiIiNTGYISIiIg05Rar9taOJLESKxERkfuovW/byghxi2CksLAQAFiJlYiIyA0VFhYiLCzM4vNukcBaXV2NixcvIiQkxGqlV7kKCgoQHR2NjIwMJsa6AF4P18Fr4Tp4LVwHr4V8giCgsLAQTZs2hY+P5cwQt+gZ8fHxQfPmzR12/NDQUH6wXAivh+vgtXAdvBaug9dCHms9IrWYwEpERESaYjBCREREmvLqYCQwMBBvvPEGF+VzEbweroPXwnXwWrgOXgvHcYsEViIiIvJcXt0zQkRERNpjMEJERESaYjBCREREmmIwQkRERJpiMEJERESa8upgZP78+YiNjUVQUBDi4+Oxbds2rZvk1rZu3Yp7770XTZs2hU6nw88//2z0vCAIePPNN9G0aVPUqVMHd9xxBw4fPmy0TVlZGaZMmYKIiAgEBwfjH//4B86fP2+0zdWrVzFq1CiEhYUhLCwMo0aNQl5enoNfnXuZNWsWbrnlFoSEhKBx48YYNmwY0tLSjLbh9XCeBQsWoEuXLvrKnQkJCfj999/1z/NaaGPWrFnQ6XSYOnWq/jFeC40IXuq7774T/P39hS+++EI4cuSI8OyzzwrBwcHCuXPntG6a21q7dq0wY8YMYeXKlQIA4aeffjJ6fvbs2UJISIiwcuVK4eDBg8Lw4cOFJk2aCAUFBfptJkyYIDRr1kxISkoS9u3bJ/Tv31/o2rWrUFlZqd9m8ODBQlxcnLBjxw5hx44dQlxcnHDPPfc462W6hUGDBglLly4VDh06JKSmpgp333230KJFC6GoqEi/Da+H86xevVpYs2aNkJaWJqSlpQmvvPKK4O/vLxw6dEgQBF4LLezZs0do2bKl0KVLF+HZZ5/VP85roQ2vDUZ69uwpTJgwweix9u3bCy+//LJGLfIspsFIdXW1EBUVJcyePVv/WGlpqRAWFiZ89tlngiAIQl5enuDv7y989913+m0uXLgg+Pj4COvWrRMEQRCOHDkiABB27dql32bnzp0CAOHYsWMOflXuKzs7WwAgbNmyRRAEXg9X0KBBA2HRokW8FhooLCwU2rRpIyQlJQm33367PhjhtdCOVw7TlJeXIzk5GYmJiUaPJyYmYseOHRq1yrOdOXMGWVlZRu95YGAgbr/9dv17npycjIqKCqNtmjZtiri4OP02O3fuRFhYGHr16qXf5tZbb0VYWBivnRX5+fkAgPDwcAC8HlqqqqrCd999h2vXriEhIYHXQgOTJk3C3XffjbvuusvocV4L7bjFqr1qy8nJQVVVFSIjI40ej4yMRFZWlkat8my176vYe37u3Dn9NgEBAWjQoIHZNrX7Z2VloXHjxmbHb9y4Ma+dBYIgYNq0abjtttsQFxcHgNdDCwcPHkRCQgJKS0tRr149/PTTT+jYsaP+5sRr4Rzfffcd9u3bh7///tvsOf670I5XBiO1dDqd0e+CIJg9RupS8p6bbiO2Pa+dZZMnT8aBAwewfft2s+d4PZynXbt2SE1NRV5eHlauXInHHnsMW7Zs0T/Pa+F4GRkZePbZZ/HHH38gKCjI4na8Fs7nlcM0ERER8PX1NYtQs7OzzSJiUkdUVBQAWH3Po6KiUF5ejqtXr1rd5tKlS2bHv3z5Mq+diClTpmD16tXYtGkTmjdvrn+c18P5AgICcNNNN6FHjx6YNWsWunbtio8++ojXwomSk5ORnZ2N+Ph4+Pn5wc/PD1u2bMHHH38MPz8//fvEa+F8XhmMBAQEID4+HklJSUaPJyUloXfv3hq1yrPFxsYiKirK6D0vLy/Hli1b9O95fHw8/P39jbbJzMzEoUOH9NskJCQgPz8fe/bs0W+ze/du5Ofn89oZEAQBkydPxqpVq7Bx40bExsYaPc/roT1BEFBWVsZr4UQDBgzAwYMHkZqaqv/p0aMHRo4cidTUVLRq1YrXQivOz5l1DbVTexcvXiwcOXJEmDp1qhAcHCycPXtW66a5rcLCQiElJUVISUkRAAhz584VUlJS9NOlZ8+eLYSFhQmrVq0SDh48KDzyyCOiU+aaN28ubNiwQdi3b59w5513ik6Z69Kli7Bz505h586dQufOnTllzsTTTz8thIWFCZs3bxYyMzP1P8XFxfpteD2cZ/r06cLWrVuFM2fOCAcOHBBeeeUVwcfHR/jjjz8EQeC10JLhbBpB4LXQitcGI4IgCJ9++qkQExMjBAQECDfffLN+2iMps2nTJgGA2c9jjz0mCELNtLk33nhDiIqKEgIDA4V+/foJBw8eNDpGSUmJMHnyZCE8PFyoU6eOcM899wjp6elG2+Tm5gojR44UQkJChJCQEGHkyJHC1atXnfQq3YPYdQAgLF26VL8Nr4fzjB07Vv+3plGjRsKAAQP0gYgg8FpoyTQY4bXQhk4QBEGbPhkiIiIiL80ZISIiItfBYISIiIg0xWCEiIiINMVghIiIiDTFYISIiIg0xWCEiIiINMVghIiIiDTFYISIiIg0xWCEiIiINMVghIiIiDTFYISIiIg09f/WwzgEGGBk1gAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame({'baseline': loss_all}) #, 'state': loss_state\n",
    "df.plot(title='Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_np = np.sqrt(np.array(loss_all))\n",
    "np.save('../model/loss_baseline.npy', loss_np)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
