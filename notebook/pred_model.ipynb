{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "import os\n",
    "import sys\n",
    "cur_dir = os.path.dirname(os.path.abspath(\"__file__\"))  # Gets the current notebook directory\n",
    "src_dir = os.path.join(cur_dir, '../')  # Constructs the path to the 'src' directory\n",
    "# Add the 'src' directory to sys.path\n",
    "if src_dir not in sys.path:\n",
    "    sys.path.append(src_dir)\n",
    "\n",
    "from src.constant import *\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from src.MyDataset import MyDataset\n",
    "from src.TraPredModel import TraPredModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookback = 20\n",
    "dir = '../data/PandasData/Original/'\n",
    "\n",
    "ds = MyDataset(lookback=lookback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shaoze/Documents/Boeing/Boeing-Trajectory-Prediction/notebook/../src/MyDataset.py:56: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:275.)\n",
      "  return torch.tensor(X), torch.tensor(y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['AGV_name', 'User_X', 'User_Y', 'AGV_X', 'AGV_Y', 'AGV_Pitch',\n",
      "       'AGV_Yaw', 'AGV_Roll', 'AGV_speed', 'GazeOrigin_X', 'GazeOrigin_Y',\n",
      "       'GazeDirection_X', 'GazeDirection_Y', 'GazeDirection_Z'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "def process_data(df_dir : str, target_freq : int = 10):\n",
    "    df = pd.read_pickle(df_dir)\n",
    "    f_per_sec = df.groupby('TimestampID').count().mean().mean()\n",
    "    resample_ratio = int(f_per_sec/target_freq)\n",
    "    df = df.iloc[::resample_ratio, :]\n",
    "    # for origin\n",
    "    df = df.drop(columns=['Confidence', 'Timestamp', 'TimestampID', \n",
    "                          'DatapointID', 'PID', 'SCN', 'U_X', 'U_Y', 'U_Z', \n",
    "                          'AGV_Z', 'User_Z', 'GazeOrigin_Z', 'User_Pitch', 'User_Yaw', 'User_Roll', \n",
    "                          'EyeTarget'], errors='ignore')\n",
    "    return df\n",
    "\n",
    "for file in os.listdir(dir):\n",
    "    if file.endswith('.pkl'):\n",
    "        df = process_data(dir+file)\n",
    "        ds.read_data(df)\n",
    "\n",
    "train, test = ds.split_data(frac=0.8, shuffle=True, batch_size=16)\n",
    "feature_dim = ds.feature_dim\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 20, 13]) torch.Size([16, 20, 13])\n",
      "7783 1946\n"
     ]
    }
   ],
   "source": [
    "for i, (X, y) in enumerate(train):\n",
    "    print(X.shape, y.shape)\n",
    "    break\n",
    "\n",
    "print(len(train), len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TraPredModel(input_size=feature_dim, lookback=lookback)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-3)\n",
    "loss_fn = nn.MSELoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af46ba74c6bd4fa5b9f38a88e9d808a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7783 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_epochs = 1\n",
    "eval_step = 100000\n",
    "# model = TraPredModel(input_size=numeric_df.shape[1], lookback=lookback)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using {device}\")\n",
    "model.to(device)\n",
    "\n",
    "train_all = len(train)\n",
    "\n",
    "loss_all = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    for step, (X_batch, y_batch) in tqdm(enumerate(train), total = train_all):\n",
    "        X_batch = X_batch.float().to(device)\n",
    "        y_batch = y_batch.float().to(device)\n",
    "\n",
    "        y_pred = model(X_batch)\n",
    "        loss = torch.mean(loss_fn(y_pred, y_batch[:, :, :2]))\n",
    "        loss_all.append(loss.item())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Validation\n",
    "        if (epoch * train_all + step + 1) % eval_step == 0:\n",
    "            print(f\"Start testing\")\n",
    "            with torch.no_grad():\n",
    "                model.eval()\n",
    "                all_test = len(test)\n",
    "                test_rmse_all = []\n",
    "                for X_test_batch, y_test_batch in tqdm(test):\n",
    "                    X_test_batch = X_test_batch.float().to(device)\n",
    "                    y_test_batch = y_test_batch.float().to(device)\n",
    "                    y_pred = model(X_test_batch)\n",
    "                    test_rmse = torch.mean(loss_fn(y_pred, y_test_batch[:, :, :2]))\n",
    "                    if not torch.isnan(test_rmse):\n",
    "                        test_rmse_all.append(test_rmse.item())\n",
    "\n",
    "                print(\"Epoch %d: test RMSE %.4f\" % (epoch, sum(test_rmse_all)/all_test))\n",
    "            \n",
    "            model.train()\n",
    "        # break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7058.70158032, 7491.86865875, 6997.30462392, ..., 2526.97368407,\n",
       "       2375.570984  , 3065.86056434])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_np = np.sqrt(np.array(loss_all))\n",
    "np.save('../model/loss_baseline.npy', loss_np)\n",
    "\n",
    "loss_np"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
